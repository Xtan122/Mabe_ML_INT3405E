{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55ec55ce",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:32.241233Z",
     "iopub.status.busy": "2025-12-12T15:19:32.240989Z",
     "iopub.status.idle": "2025-12-12T15:19:32.250225Z",
     "shell.execute_reply": "2025-12-12T15:19:32.249680Z"
    },
    "papermill": {
     "duration": 0.016644,
     "end_time": "2025-12-12T15:19:32.251505",
     "exception": false,
     "start_time": "2025-12-12T15:19:32.234861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "validate_or_submit = 'submit' # 'validate' or 'submit' or 'stresstest'\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "084f4943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:32.263065Z",
     "iopub.status.busy": "2025-12-12T15:19:32.262861Z",
     "iopub.status.idle": "2025-12-12T15:19:49.052810Z",
     "shell.execute_reply": "2025-12-12T15:19:49.051817Z"
    },
    "papermill": {
     "duration": 16.798165,
     "end_time": "2025-12-12T15:19:49.054199",
     "exception": false,
     "start_time": "2025-12-12T15:19:32.256034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ PyTorch GPU Available: Tesla T4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LightGBM GPU support detected\n",
      "\n",
      "==================================================\n",
      "GPU Configuration:\n",
      "  - XGBoost will use: GPU (cuda:0)\n",
      "  - LightGBM will use: GPU\n",
      "  - CatBoost will use: GPU\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL: Imports (Replace entire imports cell)\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange, tqdm\n",
    "import itertools\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import lightgbm\n",
    "import ast\n",
    "import gc  # NEW: For memory cleanup\n",
    "from collections import defaultdict  # NEW: For adaptive thresholding\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator, clone\n",
    "from sklearn.model_selection import cross_val_predict, GroupKFold, train_test_split, StratifiedShuffleSplit  # NEW\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Suppress NumPy warnings for cleaner output (NaN/Inf in feature engineering is expected and handled)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, module='pandas.core.arraylike')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, module='pandas.core.computation')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='xgboost.core')\n",
    "\n",
    "# Try importing CatBoost (optional)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    CATBOOST_AVAILABLE = True\n",
    "except:\n",
    "    CATBOOST_AVAILABLE = False\n",
    "    print(\"CatBoost not available\")\n",
    "\n",
    "# Check GPU availability for both PyTorch and LightGBM\n",
    "GPU_AVAILABLE = False\n",
    "LGBM_GPU_AVAILABLE = False\n",
    "\n",
    "# Check PyTorch CUDA\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        GPU_AVAILABLE = True\n",
    "        print(f\"✓ PyTorch GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "except:\n",
    "    print(\"✗ PyTorch GPU not available\")\n",
    "\n",
    "# Check LightGBM GPU support\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    # Test if GPU device is available for LightGBM\n",
    "    test_data = lgb.Dataset(np.random.rand(100, 10), label=np.random.randint(0, 2, 100))\n",
    "    test_params = {'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0, 'verbose': -1}\n",
    "    lgb.train(test_params, test_data, num_boost_round=1)\n",
    "    LGBM_GPU_AVAILABLE = True\n",
    "    print(\"✓ LightGBM GPU support detected\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ LightGBM GPU not available: {str(e)[:80]}\")\n",
    "    LGBM_GPU_AVAILABLE = False\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"GPU Configuration:\")\n",
    "print(f\"  - XGBoost will use: {'GPU (cuda:0)' if GPU_AVAILABLE else 'CPU (hist)'}\")\n",
    "print(f\"  - LightGBM will use: {'GPU' if LGBM_GPU_AVAILABLE else 'CPU'}\")\n",
    "print(f\"  - CatBoost will use: {'GPU' if GPU_AVAILABLE and CATBOOST_AVAILABLE else 'CPU'}\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75bb8b4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:49.065222Z",
     "iopub.status.busy": "2025-12-12T15:19:49.064449Z",
     "iopub.status.idle": "2025-12-12T15:19:49.075998Z",
     "shell.execute_reply": "2025-12-12T15:19:49.075270Z"
    },
    "papermill": {
     "duration": 0.017868,
     "end_time": "2025-12-12T15:19:49.077174",
     "exception": false,
     "start_time": "2025-12-12T15:19:49.059306",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: StratifiedSubsetClassifier (Replace TrainOnSubsetClassifier cell)\n",
    "# =============================================================================\n",
    "\n",
    "class StratifiedSubsetClassifier(ClassifierMixin, BaseEstimator):\n",
    "    \"\"\"Enhanced classifier with stratified sampling for balanced class distribution\n",
    "    \n",
    "    Key improvements over TrainOnSubsetClassifier:\n",
    "    - Uses StratifiedShuffleSplit to maintain class balance\n",
    "    - Better edge case handling (single class, GPU fallback)\n",
    "    - Memory efficient with float32\n",
    "    \"\"\"\n",
    "    def __init__(self, estimator, n_samples=50_000):\n",
    "        self.estimator = estimator\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def _to_numpy(self, X):\n",
    "        \"\"\"Convert to numpy float32 for memory efficiency\"\"\"\n",
    "        try:\n",
    "            return X.to_numpy(np.float32, copy=False)\n",
    "        except AttributeError:\n",
    "            return np.asarray(X, dtype=np.float32)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        Xn = self._to_numpy(X)\n",
    "        y = np.asarray(y).ravel()\n",
    "\n",
    "        # If n_samples is None → fit on full data\n",
    "        if self.n_samples is None or len(Xn) <= int(self.n_samples):\n",
    "            self.estimator.fit(Xn, y)\n",
    "        else:\n",
    "            # Stratified sampling to maintain class balance\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, train_size=int(self.n_samples), random_state=SEED)\n",
    "            try:\n",
    "                idx, _ = next(sss.split(np.zeros_like(y), y))\n",
    "                self.estimator.fit(Xn[idx], y[idx])\n",
    "            except Exception as e:\n",
    "                # Fallback to simple subsampling if stratification fails\n",
    "                print(f\"  Stratification failed, using step sampling: {str(e)[:50]}\")\n",
    "                step = max(len(Xn) // int(self.n_samples), 1)\n",
    "                self.estimator.fit(Xn[::step], y[::step])\n",
    "\n",
    "        try:\n",
    "            self.classes_ = np.asarray(self.estimator.classes_)\n",
    "        except Exception:\n",
    "            self.classes_ = np.unique(y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        Xn = self._to_numpy(X)\n",
    "        try:\n",
    "            P = self.estimator.predict_proba(Xn)\n",
    "        except Exception:\n",
    "            # Handle edge cases\n",
    "            if len(self.classes_) == 1:\n",
    "                n = len(Xn)\n",
    "                c = int(self.classes_[0])\n",
    "                if c == 1:\n",
    "                    return np.column_stack([np.zeros(n, dtype=np.float32), np.ones(n, dtype=np.float32)])\n",
    "                else:\n",
    "                    return np.column_stack([np.ones(n, dtype=np.float32), np.zeros(n, dtype=np.float32)])\n",
    "            return np.full((len(Xn), 2), 0.5, dtype=np.float32)\n",
    "\n",
    "        P = np.asarray(P, dtype=np.float32)\n",
    "        if P.ndim == 1:\n",
    "            P1 = P.astype(np.float32)\n",
    "            return np.column_stack([1.0 - P1, P1])\n",
    "        if P.shape[1] == 1 and len(self.classes_) == 2:\n",
    "            P1 = P[:, 0].astype(np.float32)\n",
    "            return np.column_stack([1.0 - P1, P1])\n",
    "        return P\n",
    "\n",
    "    def predict(self, X):\n",
    "        Xn = self._to_numpy(X)\n",
    "        try:\n",
    "            return self.estimator.predict(Xn)\n",
    "        except Exception:\n",
    "            return np.argmax(self.predict_proba(Xn), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "692c8abd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:49.087131Z",
     "iopub.status.busy": "2025-12-12T15:19:49.086899Z",
     "iopub.status.idle": "2025-12-12T15:19:49.603522Z",
     "shell.execute_reply": "2025-12-12T15:19:49.602880Z"
    },
    "papermill": {
     "duration": 0.523453,
     "end_time": "2025-12-12T15:19:49.604957",
     "exception": false,
     "start_time": "2025-12-12T15:19:49.081504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"F Beta customized for the data format of the MABe challenge.\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "class HostVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1) -> float:\n",
    "    label_frames: defaultdict[str, set[int]] = defaultdict(set) # key is video/agent/target/action from solution\n",
    "    prediction_frames: defaultdict[str, set[int]] = defaultdict(set) # key is video/agent/target/action from submission\n",
    "\n",
    "    for row in lab_solution.to_dicts():\n",
    "        label_frames[row['label_key']].update(range(row['start_frame'], row['stop_frame']))\n",
    "\n",
    "    for video in lab_solution['video_id'].unique():\n",
    "        active_labels: str = lab_solution.filter(pl.col('video_id') == video)['behaviors_labeled'].first()  # ty: ignore\n",
    "        active_labels: set[str] = set(json.loads(active_labels)) # set of agent,target,action from solution\n",
    "        predicted_mouse_pairs: defaultdict[str, set[int]] = defaultdict(set) # key is agent,target from submission\n",
    "\n",
    "        for row in lab_submission.filter(pl.col('video_id') == video).to_dicts(): # every submission row is converted to a dict\n",
    "            # Since the labels are sparse, we can't evaluate prediction keys not in the active labels.\n",
    "            if ','.join([str(row['agent_id']), str(row['target_id']), row['action']]) not in active_labels:\n",
    "                # print(f'ignoring {video}', ','.join([str(row['agent_id']), str(row['target_id']), row['action']]), active_labels)\n",
    "                continue # these submission rows are ignored\n",
    "           \n",
    "            new_frames = set(range(row['start_frame'], row['stop_frame']))\n",
    "            # Ignore truly redundant predictions.\n",
    "            new_frames = new_frames.difference(prediction_frames[row['prediction_key']])\n",
    "            prediction_pair = ','.join([str(row['agent_id']), str(row['target_id'])])\n",
    "            if predicted_mouse_pairs[prediction_pair].intersection(new_frames):\n",
    "                # A single agent can have multiple targets per frame (ex: evading all other mice) but only one action per target per frame.\n",
    "                raise HostVisibleError('Multiple predictions for the same frame from one agent/target pair')\n",
    "            prediction_frames[row['prediction_key']].update(new_frames)\n",
    "            predicted_mouse_pairs[prediction_pair].update(new_frames)\n",
    "\n",
    "    tps = defaultdict(int) # key is action\n",
    "    fns = defaultdict(int) # key is action\n",
    "    fps = defaultdict(int) # key is action\n",
    "    for key, pred_frames in prediction_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        matched_label_frames = label_frames[key]\n",
    "        tps[action] += len(pred_frames.intersection(matched_label_frames))\n",
    "        fns[action] += len(matched_label_frames.difference(pred_frames))\n",
    "        fps[action] += len(pred_frames.difference(matched_label_frames))\n",
    "\n",
    "    distinct_actions = set()\n",
    "    for key, frames in label_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        distinct_actions.add(action)\n",
    "        if key not in prediction_frames:\n",
    "            fns[action] += len(frames)\n",
    "\n",
    "    action_f1s = []\n",
    "    for action in distinct_actions:\n",
    "        # print(f\"{tps[action]:8} {fns[action]:8} {fps[action]:8}\")\n",
    "        if tps[action] + fns[action] + fps[action] == 0:\n",
    "            action_f1s.append(0)\n",
    "        else:\n",
    "            action_f1s.append((1 + beta**2) * tps[action] / ((1 + beta**2) * tps[action] + beta**2 * fns[action] + fps[action]))\n",
    "    return sum(action_f1s) / len(action_f1s)\n",
    "\n",
    "\n",
    "def mouse_fbeta(solution: pd.DataFrame, submission: pd.DataFrame, beta: float = 1) -> float:\n",
    "    \"\"\"\n",
    "    Doctests:\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10},\n",
    "    ... ])\n",
    "    >>> mouse_fbeta(solution, submission)\n",
    "    1.0\n",
    "\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 0, 'stop_frame': 10}, # Wrong action\n",
    "    ... ])\n",
    "    >>> mouse_fbeta(solution, submission)\n",
    "    0.0\n",
    "\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 15, 'stop_frame': 24, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9},\n",
    "    ... ])\n",
    "    >>> \"%.12f\" % mouse_fbeta(solution, submission)\n",
    "    '0.500000000000'\n",
    "\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 15, 'stop_frame': 24, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 345, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9, 'lab_id': 2, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 345, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 15, 'stop_frame': 24, 'lab_id': 2, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9},\n",
    "    ... ])\n",
    "    >>> \"%.12f\" % mouse_fbeta(solution, submission)\n",
    "    '0.250000000000'\n",
    "\n",
    "    >>> # Overlapping solution events, one prediction matching both.\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 10, 'stop_frame': 20, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 20},\n",
    "    ... ])\n",
    "    >>> mouse_fbeta(solution, submission)\n",
    "    1.0\n",
    "\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 30, 'stop_frame': 40, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 40},\n",
    "    ... ])\n",
    "    >>> mouse_fbeta(solution, submission)\n",
    "    0.6666666666666666\n",
    "    \"\"\"\n",
    "    if len(solution) == 0 or len(submission) == 0:\n",
    "        raise ValueError('Missing solution or submission data')\n",
    "\n",
    "    expected_cols = ['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']\n",
    "\n",
    "    for col in expected_cols:\n",
    "        if col not in solution.columns:\n",
    "            raise ValueError(f'Solution is missing column {col}')\n",
    "        if col not in submission.columns:\n",
    "            raise ValueError(f'Submission is missing column {col}')\n",
    "\n",
    "    solution: pl.DataFrame = pl.DataFrame(solution)\n",
    "    submission: pl.DataFrame = pl.DataFrame(submission)\n",
    "    assert (solution['start_frame'] <= solution['stop_frame']).all()\n",
    "    assert (submission['start_frame'] <= submission['stop_frame']).all()\n",
    "    solution_videos = set(solution['video_id'].unique())\n",
    "    # Need to align based on video IDs as we can't rely on the row IDs for handling public/private splits.\n",
    "    submission = submission.filter(pl.col('video_id').is_in(solution_videos))\n",
    "\n",
    "    solution = solution.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('label_key'),\n",
    "    )\n",
    "    submission = submission.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('prediction_key'),\n",
    "    )\n",
    "\n",
    "    lab_scores = []\n",
    "    for lab in solution['lab_id'].unique():\n",
    "        lab_solution = solution.filter(pl.col('lab_id') == lab).clone()\n",
    "        lab_videos = set(lab_solution['video_id'].unique())\n",
    "        lab_submission = submission.filter(pl.col('video_id').is_in(lab_videos)).clone()\n",
    "        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n",
    "\n",
    "    return sum(lab_scores) / len(lab_scores)\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, beta: float = 1) -> float:\n",
    "    \"\"\"\n",
    "    F1 score for the MABe Challenge\n",
    "    \"\"\"\n",
    "    solution = solution.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    submission = submission.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    return mouse_fbeta(solution, submission, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3caee89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:49.616093Z",
     "iopub.status.busy": "2025-12-12T15:19:49.615377Z",
     "iopub.status.idle": "2025-12-12T15:19:49.755601Z",
     "shell.execute_reply": "2025-12-12T15:19:49.754849Z"
    },
    "papermill": {
     "duration": 0.146754,
     "end_time": "2025-12-12T15:19:49.756987",
     "exception": false,
     "start_time": "2025-12-12T15:19:49.610233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/train.csv')\n",
    "train['n_mice'] = 4 - train[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\n",
    "train_without_mabe22 = train.query(\"~ lab_id.str.startswith('MABe22_')\")\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/test.csv')\n",
    "\n",
    "# labs = list(np.unique(train.lab_id))\n",
    "\n",
    "body_parts_tracked_list = list(np.unique(train.body_parts_tracked))\n",
    "\n",
    "# behaviors = list(train.behaviors_labeled.drop_duplicates().dropna())\n",
    "# behaviors = sorted(list({b.replace(\"'\", \"\") for bb in behaviors for b in json.loads(bb)}))\n",
    "# behaviors = [b.split(',') for b in behaviors]\n",
    "# behaviors = pd.DataFrame(behaviors, columns=['agent', 'target', 'action'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6037ac0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:49.767078Z",
     "iopub.status.busy": "2025-12-12T15:19:49.766861Z",
     "iopub.status.idle": "2025-12-12T15:19:49.772824Z",
     "shell.execute_reply": "2025-12-12T15:19:49.772105Z"
    },
    "papermill": {
     "duration": 0.012381,
     "end_time": "2025-12-12T15:19:49.773982",
     "exception": false,
     "start_time": "2025-12-12T15:19:49.761601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_solution_df(dataset):\n",
    "    \"\"\"Create the solution dataframe for validating out-of-fold predictions.\n",
    "\n",
    "    From https://www.kaggle.com/code/ambrosm/mabe-validated-baseline-without-machine-learning/\n",
    "    \n",
    "    Parameters:\n",
    "    dataset: (a subset of) the train dataframe\n",
    "    \n",
    "    Return values:\n",
    "    solution: solution dataframe in the correct format for the score() function\n",
    "    \"\"\"\n",
    "    solution = []\n",
    "    for _, row in tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "    \n",
    "        # Load annotation file\n",
    "        lab_id = row['lab_id']\n",
    "        if lab_id.startswith('MABe22'): continue\n",
    "        video_id = row['video_id']\n",
    "        path = f\"/kaggle/input/MABe-mouse-behavior-detection/train_annotation/{lab_id}/{video_id}.parquet\"\n",
    "        try:\n",
    "            annot = pd.read_parquet(path)\n",
    "        except FileNotFoundError:\n",
    "            # MABe22 and one more training file lack annotations.\n",
    "            if verbose: print(f\"No annotations for {path}\")\n",
    "            continue\n",
    "    \n",
    "        # Add all annotations to the solution\n",
    "        annot['lab_id'] = lab_id\n",
    "        annot['video_id'] = video_id\n",
    "        annot['behaviors_labeled'] = row['behaviors_labeled']\n",
    "        annot['target_id'] = np.where(annot.target_id != annot.agent_id, annot['target_id'].apply(lambda s: f\"mouse{s}\"), 'self')\n",
    "        annot['agent_id'] = annot['agent_id'].apply(lambda s: f\"mouse{s}\")\n",
    "        solution.append(annot)\n",
    "    \n",
    "    solution = pd.concat(solution)\n",
    "    return solution\n",
    "\n",
    "if validate_or_submit == 'validate':\n",
    "    solution = create_solution_df(train_without_mabe22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "366863e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:49.783350Z",
     "iopub.status.busy": "2025-12-12T15:19:49.783156Z",
     "iopub.status.idle": "2025-12-12T15:19:49.791667Z",
     "shell.execute_reply": "2025-12-12T15:19:49.790948Z"
    },
    "papermill": {
     "duration": 0.014462,
     "end_time": "2025-12-12T15:19:49.792769",
     "exception": false,
     "start_time": "2025-12-12T15:19:49.778307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if validate_or_submit == 'stresstest':\n",
    "    n_videos_per_lab = 2\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(f\"stresstest_tracking\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    stresstest = pd.concat(\n",
    "        [train.query(\"video_id == 1459695188\")] # long video from BoisterousParrot\n",
    "        + [df.sample(min(n_videos_per_lab, len(df)), random_state=1) for (_, df) in train.groupby('lab_id')])\n",
    "    for _, row in tqdm(stresstest.iterrows(), total=len(stresstest)):\n",
    "        lab_id = row['lab_id']\n",
    "        video_id = row['video_id']\n",
    "        \n",
    "        # Load video\n",
    "        path = f\"/kaggle/input/MABe-mouse-behavior-detection/train_tracking/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path)\n",
    "    \n",
    "        if video_id == 1459695188: # long video from BoisterousParrot\n",
    "            vid = pd.concat([vid] * 3) # provoke out of memory (5 is too much)\n",
    "            vid['video_frame'] = np.arange(len(vid))\n",
    "    \n",
    "        # Drop some complete frames\n",
    "        dropped_frames = list(rng.choice(np.unique(vid.video_frame), size=100, replace=False))\n",
    "        vid = vid.query(\"~ video_frame.isin(@dropped_frames)\")\n",
    "        \n",
    "        # Drop a complete bodypart\n",
    "        if rng.uniform() < 0.2:\n",
    "            dropped_bodypart = rng.choice(np.unique(vid.bodypart), size=1, replace=False)[0]\n",
    "            vid = vid.query(\"bodypart != @dropped_bodypart\")\n",
    "        \n",
    "        # Drop a mouse\n",
    "        if rng.uniform() < 0.1:\n",
    "            vid = vid.query(\"mouse_id != 1\")\n",
    "        \n",
    "        # Drop random bodyparts from random frames\n",
    "        if rng.uniform() < 0.7:\n",
    "            mask = np.ones(len(vid), dtype=bool)\n",
    "            mask[:int(0.4 * len(mask))] = False\n",
    "            rng.shuffle(mask)\n",
    "            vid = vid[mask]\n",
    "    \n",
    "        # Set random coordinates of bodyparts to nan\n",
    "        if rng.uniform() < 0.7:\n",
    "            mask = np.ones(len(vid), dtype=bool)\n",
    "            mask[:int(0.2 * len(mask))] = False\n",
    "            rng.shuffle(mask)\n",
    "            vid.loc[:, 'x'] = np.where(mask, np.nan, vid.loc[:, 'x'])\n",
    "            rng.shuffle(mask)\n",
    "            vid.loc[:, 'y'] = np.where(mask, np.nan, vid.loc[:, 'y'])\n",
    "    \n",
    "        # Save the video\n",
    "        try:\n",
    "            os.mkdir(f\"stresstest_tracking/{lab_id}\")\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        new_path = f\"stresstest_tracking/{lab_id}/{video_id}.parquet\"\n",
    "        vid.to_parquet(new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "370af95b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:49.802400Z",
     "iopub.status.busy": "2025-12-12T15:19:49.802204Z",
     "iopub.status.idle": "2025-12-12T15:19:49.817107Z",
     "shell.execute_reply": "2025-12-12T15:19:49.816394Z"
    },
    "papermill": {
     "duration": 0.021322,
     "end_time": "2025-12-12T15:19:49.818303",
     "exception": false,
     "start_time": "2025-12-12T15:19:49.796981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_body_parts =  ['headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', \n",
    "                    'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright', \n",
    "                    'spine_1', 'spine_2',\n",
    "                    'tail_middle_1', 'tail_middle_2', 'tail_midpoint']\n",
    "\n",
    "def generate_mouse_data(dataset, traintest, traintest_directory=None, generate_single=True, generate_pair=True):\n",
    "    \"\"\"Generate batches of data in coordinate representation.\n",
    "\n",
    "    The batches have variable length, and every batch can have other columns\n",
    "    for the labels, depending on what behaviors\n",
    "    were labeled for the batch.\n",
    "\n",
    "    Every video can produce zero, one or two batches.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: (subset of) train.csv or test.csv dataframe\n",
    "    traintest: either 'train' or 'test'\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    switch: either 'single' or 'pair'\n",
    "    data: dataframe containing coordinates of the body parts of a single mouse or of a pair of mice\n",
    "    meta: dataframe with columns ['video_id', 'agent_id', 'target_id', 'video_frame', 'fps']\n",
    "    label: dataframe with labels (0, 1), one column per action, only if traintest == 'train'\n",
    "    actions: list of actions to be predicted for this batch, only if traintest == 'test'\n",
    "    \"\"\"\n",
    "    assert traintest in ['train', 'test']\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n",
    "    for _, row in dataset.iterrows():\n",
    "        \n",
    "        # Load the video and pivot it sn that one frame = one row\n",
    "        lab_id = row.lab_id\n",
    "        if lab_id.startswith('MABe22'): continue\n",
    "        video_id = row.video_id\n",
    "\n",
    "        if type(row.behaviors_labeled) != str:\n",
    "            # We cannot use videos without labeled behaviors\n",
    "            print('No labeled behaviors:', lab_id, video_id, type(row.behaviors_labeled), row.behaviors_labeled)\n",
    "            continue\n",
    "\n",
    "        # Get FPS for this video\n",
    "        fps = row.get('fps_approx', 30.0)  # Default to 30 if not available\n",
    "\n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path)\n",
    "        if len(np.unique(vid.bodypart)) > 5:\n",
    "            vid = vid.query(\"~ bodypart.isin(@drop_body_parts)\")\n",
    "        pvid = vid.pivot(columns=['mouse_id', 'bodypart'], index='video_frame', values=['x', 'y'])\n",
    "        if pvid.isna().any().any():\n",
    "            if verbose and traintest == 'test': print('video with missing values', video_id, traintest, len(vid), 'frames')\n",
    "        else:\n",
    "            if verbose and traintest == 'test': print('video with all values', video_id, traintest, len(vid), 'frames')\n",
    "        del vid\n",
    "        pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T # mouse_id, body_part, xy\n",
    "        pvid /= row.pix_per_cm_approx # convert to cm\n",
    "\n",
    "        # Determine the behaviors of this video\n",
    "        vid_behaviors = json.loads(row.behaviors_labeled)\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
    "        \n",
    "        # Load the annotations\n",
    "        if traintest == 'train':\n",
    "            try:\n",
    "                annot = pd.read_parquet(path.replace('train_tracking', 'train_annotation'))\n",
    "            except FileNotFoundError:\n",
    "                # MABe22 and one more training file lack annotations.\n",
    "                # We simply drop these videos.\n",
    "                continue\n",
    "\n",
    "        # Create the single_mouse dataframes: single_mouse, single_mouse_label and single_mouse_meta\n",
    "        if generate_single:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target == 'self'\") # single-mouse behaviors of this video\n",
    "            for mouse_id_str in np.unique(vid_behaviors_subset.agent):\n",
    "                try:\n",
    "                    mouse_id = int(mouse_id_str[-1])\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"agent == @mouse_id_str\").action)\n",
    "                    single_mouse = pvid.loc[:, mouse_id]\n",
    "                    assert len(single_mouse) == len(pvid)\n",
    "                    single_mouse_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': mouse_id_str,\n",
    "                        'target_id': 'self',\n",
    "                        'video_frame': single_mouse.index,\n",
    "                        'fps': fps\n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        single_mouse_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=single_mouse.index)\n",
    "                        annot_subset = annot.query(\"(agent_id == @mouse_id) & (target_id == @mouse_id)\")\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            single_mouse_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
    "                        yield 'single', single_mouse, single_mouse_meta, single_mouse_label\n",
    "                    else:\n",
    "                        if verbose: print('- test single', video_id, mouse_id)\n",
    "                        yield 'single', single_mouse, single_mouse_meta, vid_agent_actions\n",
    "                except KeyError:\n",
    "                    pass # If there is no data for the selected agent mouse, we skip the mouse.\n",
    "\n",
    "        # Create the mouse_pair dataframes: mouse_pair, mouse_label and mouse_meta\n",
    "        if generate_pair:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target != 'self'\")\n",
    "            if len(vid_behaviors_subset) > 0:\n",
    "                for agent, target in itertools.permutations(np.unique(pvid.columns.get_level_values('mouse_id')), 2): # int8\n",
    "                    agent_str = f\"mouse{agent}\"\n",
    "                    target_str = f\"mouse{target}\"\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"(agent == @agent_str) & (target == @target_str)\").action)\n",
    "                    mouse_pair = pd.concat([pvid[agent], pvid[target]], axis=1, keys=['A', 'B'])\n",
    "                    assert len(mouse_pair) == len(pvid)\n",
    "                    mouse_pair_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': agent_str,\n",
    "                        'target_id': target_str,\n",
    "                        'video_frame': mouse_pair.index,\n",
    "                        'fps': fps\n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        mouse_pair_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=mouse_pair.index)\n",
    "                        annot_subset = annot.query(\"(agent_id == @agent) & (target_id == @target)\")\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            mouse_pair_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, mouse_pair_label\n",
    "                    else:\n",
    "                        if verbose: print('- test pair', video_id, agent, target)\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, vid_agent_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c6ec21c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:49.827725Z",
     "iopub.status.busy": "2025-12-12T15:19:49.827464Z",
     "iopub.status.idle": "2025-12-12T15:19:49.834105Z",
     "shell.execute_reply": "2025-12-12T15:19:49.833430Z"
    },
    "papermill": {
     "duration": 0.012622,
     "end_time": "2025-12-12T15:19:49.835132",
     "exception": false,
     "start_time": "2025-12-12T15:19:49.822510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: Adaptive Thresholding (Add before predict_multiclass)\n",
    "# =============================================================================\n",
    "\n",
    "# ==================== ADAPTIVE THRESHOLDING ====================\n",
    "\n",
    "action_thresholds = {\n",
    "    \"default\": 0.25,  # Lower threshold for better recall\n",
    "    \"single_default\": 0.25,\n",
    "    \"pair_default\": 0.25,\n",
    "    \"single\": {\n",
    "        \"rear\": 0.27,\n",
    "        \"rest\": 0.22,\n",
    "        \"selfgroom\": 0.23,\n",
    "    },\n",
    "    \"pair\": {\n",
    "        \"attack\": 0.23,\n",
    "        \"mount\": 0.26,\n",
    "        \"chase\": 0.24,\n",
    "        \"sniff\": 0.22,\n",
    "    }\n",
    "}\n",
    "\n",
    "def _select_threshold_map(thresholds, mode: str):\n",
    "    \"\"\"Select threshold based on mode (single/pair) and action\"\"\"\n",
    "    if isinstance(thresholds, dict):\n",
    "        # Check if mode-specific thresholds exist\n",
    "        if (\"single\" in thresholds) or (\"pair\" in thresholds):\n",
    "            base_default = float(thresholds.get(\"default\", 0.25))\n",
    "            mode_default = float(thresholds.get(f\"{mode}_default\", base_default))\n",
    "            mode_overrides = thresholds.get(mode, {}) or {}\n",
    "            out = defaultdict(lambda: mode_default)\n",
    "            out.update({str(k): float(v) for k, v in mode_overrides.items()})\n",
    "            return out\n",
    "        # Plain per-action dict\n",
    "        out = defaultdict(lambda: float(thresholds.get(\"default\", 0.25)))\n",
    "        out.update({str(k): float(v) for k, v in thresholds.items() if k != \"default\"})\n",
    "        return out\n",
    "    return defaultdict(lambda: 0.25)\n",
    "\n",
    "# Helper functions for FPS-aware feature engineering\n",
    "def _scale(window, fps, base_fps=30.0):\n",
    "    \"\"\"Scale window size by FPS ratio\"\"\"\n",
    "    return max(1, int(round(window * fps / base_fps)))\n",
    "\n",
    "def _scale_signed(offset, fps, base_fps=30.0):\n",
    "    \"\"\"Scale signed offset by FPS ratio\"\"\"\n",
    "    sign = 1 if offset >= 0 else -1\n",
    "    return sign * max(1, int(round(abs(offset) * fps / base_fps)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1824711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:49.844641Z",
     "iopub.status.busy": "2025-12-12T15:19:49.844445Z",
     "iopub.status.idle": "2025-12-12T15:19:49.855041Z",
     "shell.execute_reply": "2025-12-12T15:19:49.854328Z"
    },
    "papermill": {
     "duration": 0.016627,
     "end_time": "2025-12-12T15:19:49.856146",
     "exception": false,
     "start_time": "2025-12-12T15:19:49.839519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: Enhanced predict_multiclass (Replace predict_multiclass cell)\n",
    "# =============================================================================\n",
    "\n",
    "# Make the multi-class prediction with adaptive thresholding\n",
    "def predict_multiclass_adaptive(pred, meta, action_thresholds):\n",
    "    \"\"\"Enhanced multiclass prediction with temporal smoothing and adaptive thresholding\n",
    "    \n",
    "    Improvements:\n",
    "    - Temporal smoothing (rolling window) to reduce noise\n",
    "    - Action-specific thresholds\n",
    "    - Filter short events (< 2 frames) - more sensitive\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pred: dataframe of predicted binary probabilities, shape (n_samples, n_actions)\n",
    "    meta: dataframe with columns ['video_id', 'agent_id', 'target_id', 'video_frame', 'fps']\n",
    "    action_thresholds: dict with thresholds per action\n",
    "    \"\"\"\n",
    "    # Get FPS for adaptive smoothing\n",
    "    fps = meta['fps'].iloc[0] if 'fps' in meta.columns else 30.0\n",
    "    \n",
    "    # Apply FPS-aware temporal smoothing to reduce noise\n",
    "    smooth_window = _scale(5, fps)\n",
    "    pred_smoothed = pred.rolling(window=smooth_window, min_periods=1, center=True).mean()\n",
    "    \n",
    "    # Determine mode (single vs pair)\n",
    "    mode = 'pair'\n",
    "    try:\n",
    "        if 'target_id' in meta.columns and meta['target_id'].eq('self').all():\n",
    "            mode = 'single'\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    # Get adaptive threshold map for this mode\n",
    "    th_map = _select_threshold_map(action_thresholds, mode)\n",
    "    \n",
    "    # Find most probable action\n",
    "    ama = np.argmax(pred_smoothed, axis=1)\n",
    "    max_probs = pred_smoothed.max(axis=1)\n",
    "    \n",
    "    # Apply action-specific thresholds\n",
    "    threshold_mask = np.zeros(len(pred_smoothed), dtype=bool)\n",
    "    for i, action in enumerate(pred_smoothed.columns):\n",
    "        action_mask = (ama == i)\n",
    "        threshold = th_map[action]\n",
    "        threshold_mask |= (action_mask & (max_probs >= threshold))\n",
    "    \n",
    "    ama = np.where(threshold_mask, ama, -1)\n",
    "    ama = pd.Series(ama, index=meta.video_frame)\n",
    "    \n",
    "    # Keep only start and stop frames\n",
    "    changes_mask = (ama != ama.shift(1)).values\n",
    "    ama_changes = ama[changes_mask]\n",
    "    meta_changes = meta[changes_mask]\n",
    "    mask = ama_changes.values >= 0\n",
    "    mask[-1] = False\n",
    "    \n",
    "    submission_part = pd.DataFrame({\n",
    "        'video_id': meta_changes['video_id'][mask].values,\n",
    "        'agent_id': meta_changes['agent_id'][mask].values,\n",
    "        'target_id': meta_changes['target_id'][mask].values,\n",
    "        'action': pred.columns[ama_changes[mask].values],\n",
    "        'start_frame': ama_changes.index[mask],\n",
    "        'stop_frame': ama_changes.index[1:][mask[:-1]]\n",
    "    })\n",
    "    \n",
    "    stop_video_id = meta_changes['video_id'][1:][mask[:-1]].values\n",
    "    stop_agent_id = meta_changes['agent_id'][1:][mask[:-1]].values\n",
    "    stop_target_id = meta_changes['target_id'][1:][mask[:-1]].values\n",
    "    \n",
    "    for i in range(len(submission_part)):\n",
    "        video_id = submission_part.video_id.iloc[i]\n",
    "        agent_id = submission_part.agent_id.iloc[i]\n",
    "        target_id = submission_part.target_id.iloc[i]\n",
    "        if i < len(stop_video_id):\n",
    "            if stop_video_id[i] != video_id or stop_agent_id[i] != agent_id or stop_target_id[i] != target_id:\n",
    "                new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n",
    "                submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
    "        else:\n",
    "            new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n",
    "            submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
    "    \n",
    "    # Filter out very short events (reduced from 3 to 2 for better recall)\n",
    "    if len(submission_part) > 0:\n",
    "        duration = submission_part.stop_frame - submission_part.start_frame\n",
    "        submission_part = submission_part[duration >= 2].reset_index(drop=True)\n",
    "        if len(submission_part) > 0:\n",
    "            assert (submission_part.stop_frame > submission_part.start_frame).all(), 'stop <= start'\n",
    "    \n",
    "    if verbose: print(f'  actions found: {len(submission_part)}')\n",
    "    return submission_part\n",
    "\n",
    "# Legacy function for backward compatibility\n",
    "def predict_multiclass(pred, meta):\n",
    "    \"\"\"Legacy wrapper - uses adaptive thresholding\"\"\"\n",
    "    return predict_multiclass_adaptive(pred, meta, action_thresholds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39485db6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:49.866192Z",
     "iopub.status.busy": "2025-12-12T15:19:49.866001Z",
     "iopub.status.idle": "2025-12-12T15:19:49.902649Z",
     "shell.execute_reply": "2025-12-12T15:19:49.901937Z"
    },
    "papermill": {
     "duration": 0.042842,
     "end_time": "2025-12-12T15:19:49.903686",
     "exception": false,
     "start_time": "2025-12-12T15:19:49.860844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: FPS-Aware Advanced Feature Engineering\n",
    "# =============================================================================\n",
    "\n",
    "def add_curvature_features(X, center_x, center_y, fps):\n",
    "    \"\"\"Add curvature and turning rate features\"\"\"\n",
    "    vel_x = center_x.diff()\n",
    "    vel_y = center_y.diff()\n",
    "    \n",
    "    # Angle and turning\n",
    "    angle = np.arctan2(vel_y, vel_x)\n",
    "    angle_change = np.abs(angle.diff())\n",
    "    \n",
    "    for w in [5, 10, 20]:\n",
    "        ws = _scale(w, fps)\n",
    "        X[f'turn_rate_{w}'] = angle_change.rolling(ws, min_periods=max(1, ws // 5)).sum()\n",
    "    \n",
    "    return X\n",
    "\n",
    "def add_multiscale_features(X, center_x, center_y, fps):\n",
    "    \"\"\"Add multi-scale temporal features\"\"\"\n",
    "    for w in [3, 7, 15]:\n",
    "        ws = _scale(w, fps)\n",
    "        roll_kwargs = dict(min_periods=1, center=True)\n",
    "        \n",
    "        # Position statistics at different scales\n",
    "        X[f'x_std_{w}'] = center_x.rolling(ws, **roll_kwargs).std()\n",
    "        X[f'y_std_{w}'] = center_y.rolling(ws, **roll_kwargs).std()\n",
    "        X[f'x_skew_{w}'] = center_x.rolling(ws, **roll_kwargs).apply(lambda x: pd.Series(x).skew(), raw=False)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def add_state_features(X, center_x, center_y, fps):\n",
    "    \"\"\"Add behavioral state features (static, slow, fast)\"\"\"\n",
    "    # Velocity magnitude\n",
    "    vel_x = center_x.diff()\n",
    "    vel_y = center_y.diff()\n",
    "    speed = np.sqrt(vel_x**2 + vel_y**2)\n",
    "    \n",
    "    w = _scale(15, fps)\n",
    "    speed_smooth = speed.rolling(w, min_periods=1, center=True).mean()\n",
    "    \n",
    "    # State classification\n",
    "    X['is_static'] = (speed_smooth < 0.5).astype(float)\n",
    "    X['is_slow'] = ((speed_smooth >= 0.5) & (speed_smooth < 2.0)).astype(float)\n",
    "    X['is_fast'] = (speed_smooth >= 2.0).astype(float)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def add_longrange_features(X, center_x, center_y, fps):\n",
    "    \"\"\"Add long-range temporal features\"\"\"\n",
    "    for lag in [60, 120]:\n",
    "        l = _scale(lag, fps)\n",
    "        X[f'x_lag_{lag}'] = center_x.shift(l)\n",
    "        X[f'y_lag_{lag}'] = center_y.shift(l)\n",
    "        X[f'dist_from_{lag}'] = np.sqrt((center_x - center_x.shift(l))**2 + \n",
    "                                        (center_y - center_y.shift(l))**2)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def add_interaction_features(X, mouse_pair, avail_A, avail_B, fps):\n",
    "    \"\"\"Add advanced interaction features for pairs\"\"\"\n",
    "    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n",
    "        return X\n",
    "    \n",
    "    # Distance dynamics\n",
    "    dist = np.sqrt((mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n",
    "                   (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y'])**2)\n",
    "    \n",
    "    for w in [10, 30]:\n",
    "        ws = _scale(w, fps)\n",
    "        X[f'dist_accel_{w}'] = dist.diff().diff().rolling(ws, min_periods=1).mean()\n",
    "    \n",
    "    # Relative position change\n",
    "    if 'nose' in avail_A and 'nose' in avail_B:\n",
    "        rel_vel_x = (mouse_pair['A']['nose']['x'].diff() - mouse_pair['B']['nose']['x'].diff())\n",
    "        rel_vel_y = (mouse_pair['A']['nose']['y'].diff() - mouse_pair['B']['nose']['y'].diff())\n",
    "        X['rel_speed'] = np.sqrt(rel_vel_x**2 + rel_vel_y**2)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def transform_single(single_mouse, body_parts_tracked, fps=30.0):\n",
    "    \"\"\"Transform from cartesian coordinates to distance representation with FPS awareness.\n",
    "\n",
    "    Parameters:\n",
    "    single_mouse: dataframe with coordinates of the body parts of one mouse\n",
    "                  shape (n_samples, n_body_parts * 2)\n",
    "                  two-level MultiIndex on columns\n",
    "    body_parts_tracked: list of body parts\n",
    "    fps: frames per second of the video (for temporal feature scaling)\n",
    "    \"\"\"\n",
    "    available_body_parts = single_mouse.columns.get_level_values(0)\n",
    "    X = pd.DataFrame({\n",
    "            f\"{part1}+{part2}\": np.square(single_mouse[part1] - single_mouse[part2]).sum(axis=1, skipna=False)\n",
    "            for part1, part2 in itertools.combinations(body_parts_tracked, 2) if part1 in available_body_parts and part2 in available_body_parts\n",
    "        })\n",
    "    X = X.reindex(columns=[f\"{part1}+{part2}\" for part1, part2 in itertools.combinations(body_parts_tracked, 2)], copy=False)\n",
    "\n",
    "    # Speed features with FPS-aware lag\n",
    "    if 'ear_left' in single_mouse.columns and 'ear_right' in single_mouse.columns and 'tail_base' in single_mouse.columns:\n",
    "        lag = _scale(10, fps)\n",
    "        shifted = single_mouse[['ear_left', 'ear_right', 'tail_base']].shift(lag)\n",
    "        X = pd.concat([\n",
    "            X, \n",
    "            pd.DataFrame({\n",
    "                'speed_left': np.square(single_mouse['ear_left'] - shifted['ear_left']).sum(axis=1, skipna=False),\n",
    "                'speed_right': np.square(single_mouse['ear_right'] - shifted['ear_right']).sum(axis=1, skipna=False),\n",
    "                'speed_left2': np.square(single_mouse['ear_left'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "                'speed_right2': np.square(single_mouse['ear_right'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "            })\n",
    "        ], axis=1)\n",
    "\n",
    "    # Body angle (orientation)\n",
    "    if all(p in available_body_parts for p in ['nose', 'body_center', 'tail_base']):\n",
    "        v1 = single_mouse['nose'] - single_mouse['body_center']\n",
    "        v2 = single_mouse['tail_base'] - single_mouse['body_center']\n",
    "        X['body_ang'] = (v1['x'] * v2['x'] + v1['y'] * v2['y']) / (\n",
    "            np.sqrt(v1['x']**2 + v1['y']**2) * np.sqrt(v2['x']**2 + v2['y']**2) + 1e-6)\n",
    "\n",
    "    # Core temporal features with FPS scaling\n",
    "    if 'body_center' in available_body_parts:\n",
    "        cx = single_mouse['body_center']['x']\n",
    "        cy = single_mouse['body_center']['y']\n",
    "\n",
    "        for w in [5, 15, 30, 60]:\n",
    "            ws = _scale(w, fps)\n",
    "            roll = dict(min_periods=1, center=True)\n",
    "            X[f'cx_m{w}'] = cx.rolling(ws, **roll).mean()\n",
    "            X[f'cy_m{w}'] = cy.rolling(ws, **roll).mean()\n",
    "            X[f'cx_s{w}'] = cx.rolling(ws, **roll).std()\n",
    "            X[f'cy_s{w}'] = cy.rolling(ws, **roll).std()\n",
    "            X[f'x_rng{w}'] = cx.rolling(ws, **roll).max() - cx.rolling(ws, **roll).min()\n",
    "            X[f'y_rng{w}'] = cy.rolling(ws, **roll).max() - cy.rolling(ws, **roll).min()\n",
    "            X[f'disp{w}'] = np.sqrt(cx.diff().rolling(ws, min_periods=1).sum()**2 +\n",
    "                                     cy.diff().rolling(ws, min_periods=1).sum()**2)\n",
    "            X[f'act{w}'] = np.sqrt(cx.diff().rolling(ws, min_periods=1).var() +\n",
    "                                   cy.diff().rolling(ws, min_periods=1).var())\n",
    "            # Additional: median\n",
    "            X[f'cx_med{w}'] = cx.rolling(ws, **roll).median()\n",
    "            X[f'cy_med{w}'] = cy.rolling(ws, **roll).median()\n",
    "\n",
    "        # Advanced features\n",
    "        X = add_curvature_features(X, cx, cy, fps)\n",
    "        X = add_multiscale_features(X, cx, cy, fps)\n",
    "        X = add_state_features(X, cx, cy, fps)\n",
    "        X = add_longrange_features(X, cx, cy, fps)\n",
    "\n",
    "    # Nose-tail features with FPS-aware lags\n",
    "    if all(p in available_body_parts for p in ['nose', 'tail_base']):\n",
    "        nt_dist = np.sqrt((single_mouse['nose']['x'] - single_mouse['tail_base']['x'])**2 +\n",
    "                          (single_mouse['nose']['y'] - single_mouse['tail_base']['y'])**2)\n",
    "        for lag in [10, 20, 40]:\n",
    "            l = _scale(lag, fps)\n",
    "            X[f'nt_lg{lag}'] = nt_dist.shift(l)\n",
    "            X[f'nt_df{lag}'] = nt_dist - nt_dist.shift(l)\n",
    "\n",
    "    # Ear features with FPS-aware offsets\n",
    "    if all(p in available_body_parts for p in ['ear_left', 'ear_right']):\n",
    "        ear_d = np.sqrt((single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 +\n",
    "                        (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2)\n",
    "        for off in [-30, -20, -10, 10, 20, 30]:\n",
    "            o = _scale_signed(off, fps)\n",
    "            X[f'ear_o{off}'] = ear_d.shift(-o)\n",
    "        w = _scale(30, fps)\n",
    "        X['ear_con'] = ear_d.rolling(w, min_periods=1, center=True).std() / \\\n",
    "                       (ear_d.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n",
    "\n",
    "    return X.astype(np.float32, copy=False)\n",
    "\n",
    "def transform_pair(mouse_pair, body_parts_tracked, fps=30.0):\n",
    "    \"\"\"Transform from cartesian coordinates to distance representation with FPS awareness.\n",
    "\n",
    "    Parameters:\n",
    "    mouse_pair: dataframe with coordinates of the body parts of two mice\n",
    "                  shape (n_samples, 2 * n_body_parts * 2)\n",
    "                  three-level MultiIndex on columns\n",
    "    body_parts_tracked: list of body parts\n",
    "    fps: frames per second of the video\n",
    "    \"\"\"\n",
    "    avail_A = mouse_pair['A'].columns.get_level_values(0)\n",
    "    avail_B = mouse_pair['B'].columns.get_level_values(0)\n",
    "\n",
    "    # Inter-mouse distances\n",
    "    X = pd.DataFrame({\n",
    "        f\"12+{p1}+{p2}\": np.square(mouse_pair['A'][p1] - mouse_pair['B'][p2]).sum(axis=1, skipna=False)\n",
    "        for p1, p2 in itertools.product(body_parts_tracked, repeat=2)\n",
    "        if p1 in avail_A and p2 in avail_B\n",
    "    })\n",
    "    X = X.reindex(columns=[f\"12+{p1}+{p2}\" for p1, p2 in itertools.product(body_parts_tracked, repeat=2)], copy=False)\n",
    "\n",
    "    # Speed features with FPS-aware lag\n",
    "    if ('A', 'ear_left') in mouse_pair.columns and ('B', 'ear_left') in mouse_pair.columns:\n",
    "        lag = _scale(10, fps)\n",
    "        shA = mouse_pair['A']['ear_left'].shift(lag)\n",
    "        shB = mouse_pair['B']['ear_left'].shift(lag)\n",
    "        speeds = pd.DataFrame({\n",
    "            'sp_A': np.square(mouse_pair['A']['ear_left'] - shA).sum(axis=1, skipna=False),\n",
    "            'sp_AB': np.square(mouse_pair['A']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "            'sp_B': np.square(mouse_pair['B']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "        })\n",
    "        X = pd.concat([X, speeds], axis=1)\n",
    "\n",
    "    # Relative orientation\n",
    "    if all(p in avail_A for p in ['nose', 'tail_base']) and all(p in avail_B for p in ['nose', 'tail_base']):\n",
    "        dir_A = mouse_pair['A']['nose'] - mouse_pair['A']['tail_base']\n",
    "        dir_B = mouse_pair['B']['nose'] - mouse_pair['B']['tail_base']\n",
    "        X['rel_ori'] = (dir_A['x'] * dir_B['x'] + dir_A['y'] * dir_B['y']) / (\n",
    "            np.sqrt(dir_A['x']**2 + dir_A['y']**2) * np.sqrt(dir_B['x']**2 + dir_B['y']**2) + 1e-6)\n",
    "\n",
    "    # Approach rate with FPS-aware lag\n",
    "    if all(p in avail_A for p in ['nose']) and all(p in avail_B for p in ['nose']):\n",
    "        cur = np.square(mouse_pair['A']['nose'] - mouse_pair['B']['nose']).sum(axis=1, skipna=False)\n",
    "        lag = _scale(10, fps)\n",
    "        shA_n = mouse_pair['A']['nose'].shift(lag)\n",
    "        shB_n = mouse_pair['B']['nose'].shift(lag)\n",
    "        past = np.square(shA_n - shB_n).sum(axis=1, skipna=False)\n",
    "        X['appr'] = cur - past\n",
    "\n",
    "    # Distance bins (cm; unchanged by fps)\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        cd = np.sqrt((mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n",
    "                     (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y'])**2)\n",
    "        X['v_cls'] = (cd < 5.0).astype(float)\n",
    "        X['cls']   = ((cd >= 5.0) & (cd < 15.0)).astype(float)\n",
    "        X['med']   = ((cd >= 15.0) & (cd < 30.0)).astype(float)\n",
    "        X['far']   = (cd >= 30.0).astype(float)\n",
    "\n",
    "    # Temporal interaction features with FPS scaling\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        cd_full = np.square(mouse_pair['A']['body_center'] - mouse_pair['B']['body_center']).sum(axis=1, skipna=False)\n",
    "\n",
    "        for w in [5, 15, 30, 60]:\n",
    "            ws = _scale(w, fps)\n",
    "            roll = dict(min_periods=1, center=True)\n",
    "            X[f'd_m{w}']  = cd_full.rolling(ws, **roll).mean()\n",
    "            X[f'd_s{w}']  = cd_full.rolling(ws, **roll).std()\n",
    "            X[f'd_mn{w}'] = cd_full.rolling(ws, **roll).min()\n",
    "            X[f'd_mx{w}'] = cd_full.rolling(ws, **roll).max()\n",
    "            X[f'd_med{w}'] = cd_full.rolling(ws, **roll).median()\n",
    "\n",
    "            d_var = cd_full.rolling(ws, **roll).var()\n",
    "            X[f'int{w}'] = 1 / (1 + d_var)\n",
    "\n",
    "            Axd = mouse_pair['A']['body_center']['x'].diff()\n",
    "            Ayd = mouse_pair['A']['body_center']['y'].diff()\n",
    "            Bxd = mouse_pair['B']['body_center']['x'].diff()\n",
    "            Byd = mouse_pair['B']['body_center']['y'].diff()\n",
    "            coord = Axd * Bxd + Ayd * Byd\n",
    "            X[f'co_m{w}'] = coord.rolling(ws, **roll).mean()\n",
    "            X[f'co_s{w}'] = coord.rolling(ws, **roll).std()\n",
    "\n",
    "    # Nose-nose dynamics with FPS-aware lags\n",
    "    if 'nose' in avail_A and 'nose' in avail_B:\n",
    "        nn = np.sqrt((mouse_pair['A']['nose']['x'] - mouse_pair['B']['nose']['x'])**2 +\n",
    "                     (mouse_pair['A']['nose']['y'] - mouse_pair['B']['nose']['y'])**2)\n",
    "        for lag in [10, 20, 40]:\n",
    "            l = _scale(lag, fps)\n",
    "            X[f'nn_lg{lag}']  = nn.shift(l)\n",
    "            X[f'nn_ch{lag}']  = nn - nn.shift(l)\n",
    "            is_cl = (nn < 10.0).astype(float)\n",
    "            X[f'cl_ps{lag}']  = is_cl.rolling(l, min_periods=1).mean()\n",
    "\n",
    "    # Velocity alignment with FPS-aware offsets\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        Avx = mouse_pair['A']['body_center']['x'].diff()\n",
    "        Avy = mouse_pair['A']['body_center']['y'].diff()\n",
    "        Bvx = mouse_pair['B']['body_center']['x'].diff()\n",
    "        Bvy = mouse_pair['B']['body_center']['y'].diff()\n",
    "        val = (Avx * Bvx + Avy * Bvy) / (np.sqrt(Avx**2 + Avy**2) * np.sqrt(Bvx**2 + Bvy**2) + 1e-6)\n",
    "\n",
    "        for off in [-30, -20, -10, 0, 10, 20, 30]:\n",
    "            o = _scale_signed(off, fps)\n",
    "            X[f'va_{off}'] = val.shift(-o)\n",
    "\n",
    "        w = _scale(30, fps)\n",
    "        X['int_con'] = cd_full.rolling(w, min_periods=1, center=True).std() / \\\n",
    "                       (cd_full.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n",
    "\n",
    "        # Advanced interaction\n",
    "        X = add_interaction_features(X, mouse_pair, avail_A, avail_B, fps)\n",
    "\n",
    "    return X.astype(np.float32, copy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a41bcfe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:49.913555Z",
     "iopub.status.busy": "2025-12-12T15:19:49.913382Z",
     "iopub.status.idle": "2025-12-12T15:19:49.920649Z",
     "shell.execute_reply": "2025-12-12T15:19:49.920109Z"
    },
    "papermill": {
     "duration": 0.013576,
     "end_time": "2025-12-12T15:19:49.921605",
     "exception": false,
     "start_time": "2025-12-12T15:19:49.908029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: Enhanced cross_validate_classifier (Replace in cross_validate_classifier)\n",
    "# =============================================================================\n",
    "\n",
    "# ADD this at the beginning of cross_validate_classifier function,\n",
    "# right after the function definition line:\n",
    "\n",
    "def cross_validate_classifier(binary_classifier, X, label, meta):\n",
    "    \"\"\"Cross-validate a binary classifier per action and a multi-class classifier over all actions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    binary_classifier: classifier with predict_proba (can be a list of classifiers for ensemble)\n",
    "    X: 2d array-like (distance representation) of shape (n_samples, n_features)\n",
    "    label: dataframe with binary targets (one column per action, may have missing values), index doesn't matter\n",
    "    meta: dataframe with columns ['video_id', 'agent_id', 'target_id', 'video_frame'], index doesn't matter\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    appends to f1_list (binary) and submission_list (multi-class)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Cross-validate a binary classifier for every action\n",
    "    oof = pd.DataFrame(index=meta.video_frame) # will get a column per action\n",
    "    for action in label.columns:\n",
    "        # Filter for samples (video frames) with a defined target (i.e., target is not nan)\n",
    "        action_mask = ~ label[action].isna().values\n",
    "        X_action = X[action_mask]\n",
    "        y_action = label[action][action_mask].values.astype(int)\n",
    "        p = y_action.mean()\n",
    "        baseline_score = p / (1 + p)\n",
    "        groups_action = meta.video_id[action_mask] # ensure validation has unseen videos\n",
    "        if len(np.unique(groups_action)) < 5:\n",
    "            continue # GroupKFold would fail with fewer than n_splits groups\n",
    "\n",
    "        if not (y_action == 0).all():\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "                # Use first model from ensemble for cross-validation\n",
    "                if isinstance(binary_classifier, list):\n",
    "                    oof_action = cross_val_predict(binary_classifier[0], X_action, y_action, \n",
    "                                                   groups=groups_action, cv=GroupKFold(), method='predict_proba')\n",
    "                else:\n",
    "                    oof_action = cross_val_predict(binary_classifier, X_action, y_action, \n",
    "                                                   groups=groups_action, cv=GroupKFold(), method='predict_proba')\n",
    "            oof_action = oof_action[:, 1]\n",
    "        else:\n",
    "            oof_action = np.zeros(len(y_action))\n",
    "        \n",
    "        # Use adaptive threshold for this action\n",
    "        mode = 'single' if 'target_id' in meta.columns and meta['target_id'].eq('self').all() else 'pair'\n",
    "        th_map = _select_threshold_map(action_thresholds, mode)\n",
    "        action_threshold = th_map[action]\n",
    "        \n",
    "        f1 = f1_score(y_action, (oof_action >= action_threshold), zero_division=0)\n",
    "        ch = '>' if f1 > baseline_score else '=' if f1 == baseline_score else '<'\n",
    "        print(f\"  F1: {f1:.3f} {ch} ({baseline_score:.3f}) {action} (th={action_threshold:.3f})\")\n",
    "        f1_list.append((body_parts_tracked_str, action, f1))\n",
    "        oof_column = np.zeros(len(label))\n",
    "        oof_column[action_mask] = oof_action\n",
    "        oof[action] = oof_column\n",
    "\n",
    "    # Make the multi-class prediction with adaptive thresholding\n",
    "    submission_part = predict_multiclass_adaptive(oof, meta, action_thresholds)\n",
    "    submission_list.append(submission_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b51cd033",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:49.931438Z",
     "iopub.status.busy": "2025-12-12T15:19:49.931252Z",
     "iopub.status.idle": "2025-12-12T15:19:49.945304Z",
     "shell.execute_reply": "2025-12-12T15:19:49.944551Z"
    },
    "papermill": {
     "duration": 0.020411,
     "end_time": "2025-12-12T15:19:49.946314",
     "exception": false,
     "start_time": "2025-12-12T15:19:49.925903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: Enhanced submit function with FPS awareness\n",
    "# =============================================================================\n",
    "\n",
    "def submit(body_parts_tracked_str, switch_tr, models, model_weights, X_tr, label, meta):\n",
    "    \"\"\"Produce a submission file for the selected subset of the test data.\n",
    "    \n",
    "    Enhanced with:\n",
    "    - Ensemble of multiple models with weighted voting\n",
    "    - Memory optimization (float32, gc.collect)\n",
    "    - FPS-aware feature transformation\n",
    "    - Robust error handling for imbalanced classes\n",
    "    - LightGBM on CPU for stability, XGBoost/CatBoost on GPU\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    body_parts_tracked_str: subset of body parts for filtering the test set\n",
    "    switch_tr: 'single' or 'pair'\n",
    "    models: list of classifiers for ensemble\n",
    "    model_weights: weights for each model in ensemble\n",
    "    X_tr: training features as 2d array-like of shape (n_samples, n_features)\n",
    "    label: dataframe with binary targets (one column per action, may have missing values)\n",
    "    meta: dataframe with columns ['video_id', 'agent_id', 'target_id', 'video_frame', 'fps']\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    appends to submission_list\n",
    "    \n",
    "    \"\"\"\n",
    "    # Train ensemble of models for every action (MEMORY OPTIMIZED)\n",
    "    X_tr_np = X_tr.to_numpy(np.float32, copy=False) if hasattr(X_tr, 'to_numpy') else np.asarray(X_tr, dtype=np.float32)\n",
    "    \n",
    "    model_list = []  # will store (action, [model1, model2, ...]) tuples\n",
    "    for action in label.columns:\n",
    "        action_mask = ~ label[action].isna().values\n",
    "        y_action = label[action][action_mask].values.astype(int)\n",
    "        \n",
    "        # Enhanced class balance checking\n",
    "        n_positives = np.sum(y_action)\n",
    "        n_total = len(y_action)\n",
    "        \n",
    "        # Only train if:\n",
    "        # - Not all zeros\n",
    "        # - At least 10 positive samples (increased from 5)\n",
    "        # - Positive samples < 99% of total (avoid extreme imbalance)\n",
    "        if not (y_action == 0).all() and n_positives >= 10 and n_positives < n_total * 0.99:\n",
    "            trained_models = []\n",
    "            idx = np.flatnonzero(action_mask)\n",
    "            \n",
    "            # Train all models in the ensemble with robust error handling\n",
    "            for i, model in enumerate(models):\n",
    "                try:\n",
    "                    model_clone = clone(model)\n",
    "                    model_clone.fit(X_tr_np[idx], y_action)\n",
    "                    trained_models.append(model_clone)\n",
    "                except Exception as e:\n",
    "                    error_msg = str(e)\n",
    "                    # Handle specific LightGBM error\n",
    "                    if 'best_split_info.left_count' in error_msg:\n",
    "                        if verbose:\n",
    "                            print(f'  Stratification failed, using step sampling: {error_msg[:50]}...')\n",
    "                        try:\n",
    "                            # Fallback to step sampling\n",
    "                            step = max(len(idx) // 50000, 1)\n",
    "                            model_clone = clone(model)\n",
    "                            model_clone.fit(X_tr_np[idx][::step], y_action[::step])\n",
    "                            trained_models.append(model_clone)\n",
    "                        except Exception as e2:\n",
    "                            if verbose:\n",
    "                                print(f'    Model training failed for {action}: {str(e2)[:50]}...')\n",
    "                            continue\n",
    "                    else:\n",
    "                        if verbose:\n",
    "                            print(f'    Model training failed for {action}: {error_msg[:50]}...')\n",
    "                        continue\n",
    "            \n",
    "            if len(trained_models) > 0:\n",
    "                model_list.append((action, trained_models))\n",
    "            elif verbose:\n",
    "                print(f'    No models trained successfully for {action}')\n",
    "    \n",
    "    # Clean up training data from memory\n",
    "    del X_tr_np\n",
    "    gc.collect()\n",
    "\n",
    "    # Compute test predictions in batches\n",
    "    body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "    if len(body_parts_tracked) > 5:\n",
    "        body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "    \n",
    "    if validate_or_submit == 'submit':\n",
    "        test_subset = test[test.body_parts_tracked == body_parts_tracked_str]\n",
    "        generator = generate_mouse_data(test_subset, 'test',\n",
    "                                        generate_single=(switch_tr == 'single'), \n",
    "                                        generate_pair=(switch_tr == 'pair'))\n",
    "    else:\n",
    "        test_subset = stresstest.query(\"body_parts_tracked == @body_parts_tracked_str\")\n",
    "        generator = generate_mouse_data(test_subset, 'test',\n",
    "                                        traintest_directory='stresstest_tracking',\n",
    "                                        generate_single=(switch_tr == 'single'),\n",
    "                                        generate_pair=(switch_tr == 'pair'))\n",
    "    \n",
    "    if verbose: print(f\"n_videos: {len(test_subset)}, n_models: {len(models)}\")\n",
    "    \n",
    "    for switch_te, data_te, meta_te, actions_te in generator:\n",
    "        assert switch_te == switch_tr\n",
    "        try:\n",
    "            # Get FPS for this video\n",
    "            fps = meta_te['fps'].iloc[0] if 'fps' in meta_te.columns else 30.0\n",
    "            \n",
    "            # Transform from coordinate representation into distance representation (FPS-aware)\n",
    "            if switch_te == 'single':\n",
    "                X_te = transform_single(data_te, body_parts_tracked, fps)\n",
    "            else:\n",
    "                X_te = transform_pair(data_te, body_parts_tracked, fps)\n",
    "            \n",
    "            if verbose and len(X_te) == 0: print(\"ERROR: X_te is empty\")\n",
    "            \n",
    "            # MEMORY OPTIMIZATION: Convert to float32 and numpy\n",
    "            X_te_np = X_te.to_numpy(np.float32, copy=False) if hasattr(X_te, 'to_numpy') else np.asarray(X_te, dtype=np.float32)\n",
    "            del X_te, data_te\n",
    "            gc.collect()\n",
    "            \n",
    "            # Compute binary predictions using weighted ensemble\n",
    "            pred = pd.DataFrame(index=meta_te.video_frame)\n",
    "            for action, trained_models in model_list:\n",
    "                if action in actions_te:\n",
    "                    # Get predictions from all models\n",
    "                    probs = []\n",
    "                    for model in trained_models:\n",
    "                        try:\n",
    "                            probs.append(model.predict_proba(X_te_np)[:, 1])\n",
    "                        except Exception as e:\n",
    "                            if verbose: print(f\"    Prediction failed: {str(e)[:30]}\")\n",
    "                    \n",
    "                    if len(probs) > 0:\n",
    "                        # Weighted average\n",
    "                        if len(probs) == len(model_weights):\n",
    "                            pred[action] = np.average(probs, axis=0, weights=model_weights)\n",
    "                        else:\n",
    "                            pred[action] = np.mean(probs, axis=0)\n",
    "            \n",
    "            del X_te_np\n",
    "            gc.collect()\n",
    "            \n",
    "            # Compute multiclass predictions with adaptive thresholding\n",
    "            if pred.shape[1] != 0:\n",
    "                submission_part = predict_multiclass_adaptive(pred, meta_te, action_thresholds)\n",
    "                submission_list.append(submission_part)\n",
    "            else:\n",
    "                if verbose: print(f\"  ERROR: no useful training data\")\n",
    "                \n",
    "        except KeyError as e:\n",
    "            if verbose: print(f'  ERROR: KeyError because of missing bodypart ({switch_tr}): {str(e)[:50]}')\n",
    "            try:\n",
    "                del data_te\n",
    "            except:\n",
    "                pass\n",
    "            gc.collect()\n",
    "        except Exception as e:\n",
    "            if verbose: print(f'  ERROR: {str(e)[:80]}')\n",
    "            try:\n",
    "                del data_te\n",
    "            except:\n",
    "                pass\n",
    "            gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15e6def4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T15:19:49.956509Z",
     "iopub.status.busy": "2025-12-12T15:19:49.956332Z",
     "iopub.status.idle": "2025-12-12T17:48:03.647939Z",
     "shell.execute_reply": "2025-12-12T17:48:03.646898Z"
    },
    "papermill": {
     "duration": 8893.710994,
     "end_time": "2025-12-12T17:48:03.661730",
     "exception": false,
     "start_time": "2025-12-12T15:19:49.950736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Processing videos with ['body_center', 'ear_left', 'ear_right', 'headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', 'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright', 'lateral_left', 'lateral_right', 'neck', 'nose', 'tail_base', 'tail_midpoint', 'tail_tip']\n",
      "\n",
      "============================================================\n",
      "  🚀 OPTIMIZED ENSEMBLE: 5 STRONG MODELS\n",
      "  LightGBM: CPU (stable for rare classes)\n",
      "  XGBoost:  GPU\n",
      "  CatBoost: GPU\n",
      "============================================================\n",
      "\n",
      "  ✓ Ensemble configured: 5 models\n",
      "    Weights: [0.25, 0.2, 0.3, 0.15, 0.1]\n",
      "    Sample sizes: ['461,538', '300,000', '400,000', '600,000', '600,000']\n",
      "X_tr.shape=(544859, 115)\n",
      "n_videos: 1, n_models: 5\n",
      "video with missing values 438887472 test 529471 frames\n",
      "- test single 438887472 1\n",
      "  actions found: 15\n",
      "- test single 438887472 2\n",
      "  actions found: 89\n",
      "- test single 438887472 3\n",
      "  actions found: 58\n",
      "- test single 438887472 4\n",
      "  actions found: 131\n",
      "X_tr.shape=(1744248, 142)\n",
      "n_videos: 1, n_models: 5\n",
      "video with missing values 438887472 test 529471 frames\n",
      "- test pair 438887472 1 2\n",
      "  actions found: 0\n",
      "- test pair 438887472 1 3\n",
      "  actions found: 1\n",
      "- test pair 438887472 1 4\n",
      "  actions found: 8\n",
      "- test pair 438887472 2 1\n",
      "  actions found: 12\n",
      "- test pair 438887472 2 3\n",
      "  actions found: 21\n",
      "- test pair 438887472 2 4\n",
      "  actions found: 26\n",
      "- test pair 438887472 3 1\n",
      "  actions found: 17\n",
      "- test pair 438887472 3 2\n",
      "  actions found: 19\n",
      "- test pair 438887472 3 4\n",
      "  actions found: 20\n",
      "- test pair 438887472 4 1\n",
      "  actions found: 52\n",
      "- test pair 438887472 4 2\n",
      "  actions found: 45\n",
      "- test pair 438887472 4 3\n",
      "  actions found: 51\n",
      "\n",
      "2. Processing videos with ['body_center', 'ear_left', 'ear_right', 'hip_left', 'hip_right', 'lateral_left', 'lateral_right', 'nose', 'spine_1', 'spine_2', 'tail_base', 'tail_middle_1', 'tail_middle_2', 'tail_tip']\n",
      "\n",
      "============================================================\n",
      "  🚀 OPTIMIZED ENSEMBLE: 5 STRONG MODELS\n",
      "  LightGBM: CPU (stable for rare classes)\n",
      "  XGBoost:  GPU\n",
      "  CatBoost: GPU\n",
      "============================================================\n",
      "\n",
      "  ✓ Ensemble configured: 5 models\n",
      "    Weights: [0.25, 0.2, 0.3, 0.15, 0.1]\n",
      "    Sample sizes: ['461,538', '300,000', '400,000', '600,000', '600,000']\n",
      "X_tr.shape=(478728, 124)\n",
      "n_videos: 0, n_models: 5\n",
      "X_tr.shape=(628714, 161)\n",
      "n_videos: 0, n_models: 5\n",
      "\n",
      "3. Processing videos with ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'neck', 'nose', 'tail_base', 'tail_midpoint', 'tail_tip']\n",
      "\n",
      "============================================================\n",
      "  🚀 OPTIMIZED ENSEMBLE: 5 STRONG MODELS\n",
      "  LightGBM: CPU (stable for rare classes)\n",
      "  XGBoost:  GPU\n",
      "  CatBoost: GPU\n",
      "============================================================\n",
      "\n",
      "  ✓ Ensemble configured: 5 models\n",
      "    Weights: [0.25, 0.2, 0.3, 0.15, 0.1]\n",
      "    Sample sizes: ['461,538', '300,000', '400,000', '600,000', '600,000']\n",
      "X_tr.shape=(1941885, 115)\n",
      "n_videos: 0, n_models: 5\n",
      "X_tr.shape=(5880720, 142)\n",
      "n_videos: 0, n_models: 5\n",
      "\n",
      "4. Processing videos with ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'nose', 'tail_base', 'tail_tip']\n",
      "\n",
      "============================================================\n",
      "  🚀 OPTIMIZED ENSEMBLE: 5 STRONG MODELS\n",
      "  LightGBM: CPU (stable for rare classes)\n",
      "  XGBoost:  GPU\n",
      "  CatBoost: GPU\n",
      "============================================================\n",
      "\n",
      "  ✓ Ensemble configured: 5 models\n",
      "    Weights: [0.25, 0.2, 0.3, 0.15, 0.1]\n",
      "    Sample sizes: ['461,538', '300,000', '400,000', '600,000', '600,000']\n",
      "X_tr.shape=(2534176, 125)\n",
      "n_videos: 0, n_models: 5\n",
      "\n",
      "5. Processing videos with ['body_center', 'ear_left', 'ear_right', 'lateral_left', 'lateral_right', 'nose', 'tail_base']\n",
      "No labeled behaviors: SparklingTapir 139713291 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 167444193 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 329031399 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 361341393 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 484405601 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 610412175 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 687999061 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 801328824 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 834408298 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 1085312517 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 1366115611 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 1430299100 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 1543851393 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 1588709555 <class 'float'> nan\n",
      "No labeled behaviors: SparklingTapir 1772737271 <class 'float'> nan\n",
      "\n",
      "============================================================\n",
      "  🚀 OPTIMIZED ENSEMBLE: 5 STRONG MODELS\n",
      "  LightGBM: CPU (stable for rare classes)\n",
      "  XGBoost:  GPU\n",
      "  CatBoost: GPU\n",
      "============================================================\n",
      "\n",
      "  ✓ Ensemble configured: 5 models\n",
      "    Weights: [0.25, 0.2, 0.3, 0.15, 0.1]\n",
      "    Sample sizes: ['461,538', '300,000', '400,000', '600,000', '600,000']\n",
      "X_tr.shape=(1849144, 110)\n",
      "n_videos: 0, n_models: 5\n",
      "\n",
      "6. Processing videos with ['body_center', 'ear_left', 'ear_right', 'nose', 'tail_base']\n",
      "\n",
      "============================================================\n",
      "  🚀 OPTIMIZED ENSEMBLE: 5 STRONG MODELS\n",
      "  LightGBM: CPU (stable for rare classes)\n",
      "  XGBoost:  GPU\n",
      "  CatBoost: GPU\n",
      "============================================================\n",
      "\n",
      "  ✓ Ensemble configured: 5 models\n",
      "    Weights: [0.25, 0.2, 0.3, 0.15, 0.1]\n",
      "    Sample sizes: ['461,538', '300,000', '400,000', '600,000', '600,000']\n",
      "X_tr.shape=(708496, 89)\n",
      "n_videos: 0, n_models: 5\n",
      "X_tr.shape=(10212910, 86)\n",
      "n_videos: 0, n_models: 5\n",
      "\n",
      "7. Processing videos with ['ear_left', 'ear_right', 'head', 'tail_base']\n",
      "\n",
      "============================================================\n",
      "  🚀 OPTIMIZED ENSEMBLE: 5 STRONG MODELS\n",
      "  LightGBM: CPU (stable for rare classes)\n",
      "  XGBoost:  GPU\n",
      "  CatBoost: GPU\n",
      "============================================================\n",
      "\n",
      "  ✓ Ensemble configured: 5 models\n",
      "    Weights: [0.25, 0.2, 0.3, 0.15, 0.1]\n",
      "    Sample sizes: ['461,538', '300,000', '400,000', '600,000', '600,000']\n",
      "X_tr.shape=(899134, 17)\n",
      "n_videos: 0, n_models: 5\n",
      "X_tr.shape=(899134, 19)\n",
      "n_videos: 0, n_models: 5\n",
      "\n",
      "8. Processing videos with ['ear_left', 'ear_right', 'hip_left', 'hip_right', 'neck', 'nose', 'tail_base']\n",
      "\n",
      "============================================================\n",
      "  🚀 OPTIMIZED ENSEMBLE: 5 STRONG MODELS\n",
      "  LightGBM: CPU (stable for rare classes)\n",
      "  XGBoost:  GPU\n",
      "  CatBoost: GPU\n",
      "============================================================\n",
      "\n",
      "  ✓ Ensemble configured: 5 models\n",
      "    Weights: [0.25, 0.2, 0.3, 0.15, 0.1]\n",
      "    Sample sizes: ['461,538', '300,000', '400,000', '600,000', '600,000']\n",
      "X_tr.shape=(3020371, 38)\n",
      "n_videos: 0, n_models: 5\n",
      "X_tr.shape=(23086736, 63)\n",
      "n_videos: 0, n_models: 5\n",
      "\n",
      "9. Processing videos with ['ear_left', 'ear_right', 'nose', 'tail_base', 'tail_tip']\n",
      "\n",
      "============================================================\n",
      "  🚀 OPTIMIZED ENSEMBLE: 5 STRONG MODELS\n",
      "  LightGBM: CPU (stable for rare classes)\n",
      "  XGBoost:  GPU\n",
      "  CatBoost: GPU\n",
      "============================================================\n",
      "\n",
      "  ✓ Ensemble configured: 5 models\n",
      "    Weights: [0.25, 0.2, 0.3, 0.15, 0.1]\n",
      "    Sample sizes: ['461,538', '300,000', '400,000', '600,000', '600,000']\n",
      "X_tr.shape=(329777, 27)\n",
      "n_videos: 0, n_models: 5\n",
      "X_tr.shape=(1774618, 39)\n",
      "n_videos: 0, n_models: 5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "f1_list = []\n",
    "submission_list = []\n",
    "for section in range(1, len(body_parts_tracked_list)): # skip index 0 (MABe22)\n",
    "    body_parts_tracked_str = body_parts_tracked_list[section]\n",
    "    try:\n",
    "        body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "        print(f\"{section}. Processing videos with {body_parts_tracked}\")\n",
    "        if len(body_parts_tracked) > 5:\n",
    "            body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "    \n",
    "        # We read all training data which match the body parts tracked\n",
    "        train_subset = train[train.body_parts_tracked == body_parts_tracked_str]\n",
    "        single_mouse_list = []\n",
    "        single_mouse_label_list = []\n",
    "        single_mouse_meta_list = []\n",
    "        mouse_pair_list = []\n",
    "        mouse_pair_label_list = []\n",
    "        mouse_pair_meta_list = []\n",
    "    \n",
    "        for switch, data, meta, label in generate_mouse_data(train_subset, 'train'):\n",
    "            if switch == 'single':\n",
    "                single_mouse_list.append(data)\n",
    "                single_mouse_meta_list.append(meta)\n",
    "                single_mouse_label_list.append(label)\n",
    "            else:\n",
    "                mouse_pair_list.append(data)\n",
    "                mouse_pair_meta_list.append(meta)\n",
    "                mouse_pair_label_list.append(label)\n",
    "    \n",
    "        # =============================================================================\n",
    "        # OPTIMIZED ENSEMBLE: 5 STRONG MODELS (Based on Top Kaggle Notebooks)\n",
    "        # Key improvements:\n",
    "        # - Reduced from 7-9 to 5 diverse, powerful models\n",
    "        # - Increased n_estimators (350-400 vs 200-300)\n",
    "        # - Better regularization (min_child_samples: 20-40 vs 5)\n",
    "        # - Dynamic sample sizes (300K-500K) for efficiency\n",
    "        # - Stronger learning rates for faster convergence\n",
    "        # =============================================================================\n",
    "        \n",
    "        base_n_samples = 600_000  # Base sample size\n",
    "        models = []\n",
    "        \n",
    "        # Configure device for each model type\n",
    "        lgbm_device = 'cpu'  # CPU for stability with imbalanced data\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"  🚀 OPTIMIZED ENSEMBLE: 5 STRONG MODELS\")\n",
    "            print(f\"  LightGBM: CPU (stable for rare classes)\")\n",
    "            print(f\"  XGBoost:  {'GPU' if GPU_AVAILABLE else 'CPU'}\")\n",
    "            print(f\"  CatBoost: {'GPU' if CATBOOST_AVAILABLE and GPU_AVAILABLE else 'CPU'}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # Base LightGBM parameters - STRONGER regularization\n",
    "        lgbm_base_params = {\n",
    "            'device': lgbm_device,\n",
    "            'verbose': -1,\n",
    "            'min_gain_to_split': 0.0,\n",
    "            'min_sum_hessian_in_leaf': 1e-3,\n",
    "        }\n",
    "        \n",
    "        # =============================================================================\n",
    "        # MODEL 1: LightGBM - Strong Baseline (400 estimators)\n",
    "        # =============================================================================\n",
    "        models.append(make_pipeline(\n",
    "            SimpleImputer(),\n",
    "            StratifiedSubsetClassifier(\n",
    "                lightgbm.LGBMClassifier(\n",
    "                    n_estimators=400,           # Increased from 300\n",
    "                    learning_rate=0.07,         # Increased from 0.06\n",
    "                    min_child_samples=40,       # Increased from 5 for stability\n",
    "                    num_leaves=31,\n",
    "                    max_depth=-1,               # No limit, controlled by leaves\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.8,\n",
    "                    reg_alpha=0.0,\n",
    "                    reg_lambda=0.0,\n",
    "                    **lgbm_base_params,\n",
    "                    random_state=SEED,\n",
    "                    bagging_seed=SEED,\n",
    "                    feature_fraction_seed=SEED,\n",
    "                    data_random_seed=SEED\n",
    "                ), int(base_n_samples / 1.3)    # ~460K samples\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        # =============================================================================\n",
    "        # MODEL 2: LightGBM - Deeper Trees (300 estimators)\n",
    "        # =============================================================================\n",
    "        models.append(make_pipeline(\n",
    "            SimpleImputer(),\n",
    "            StratifiedSubsetClassifier(\n",
    "                lightgbm.LGBMClassifier(\n",
    "                    n_estimators=300,           # Good balance\n",
    "                    learning_rate=0.1,          # Higher for faster convergence\n",
    "                    min_child_samples=20,       # Increased from 5\n",
    "                    num_leaves=63,              # More leaves for complexity\n",
    "                    max_depth=8,                # Deeper trees\n",
    "                    subsample=0.7,\n",
    "                    colsample_bytree=0.9,\n",
    "                    reg_alpha=0.1,              # Stronger regularization\n",
    "                    reg_lambda=0.1,\n",
    "                    **lgbm_base_params,\n",
    "                    random_state=SEED+1,\n",
    "                    bagging_seed=SEED+1,\n",
    "                    feature_fraction_seed=SEED+1,\n",
    "                    data_random_seed=SEED+1\n",
    "                ), int(base_n_samples / 2)      # ~300K samples\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        # =============================================================================\n",
    "        # MODEL 3: XGBoost - Strong GPU Accelerated (400 estimators)\n",
    "        # =============================================================================\n",
    "        xgb_params = {\n",
    "            'n_estimators': 400,                # Increased from 250\n",
    "            'learning_rate': 0.08,\n",
    "            'max_depth': 6,\n",
    "            'min_child_weight': 5,              # Increased from 1 for stability\n",
    "            'subsample': 0.8,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'reg_alpha': 0.0,\n",
    "            'reg_lambda': 0.0,\n",
    "            'tree_method': 'hist',\n",
    "            'device': 'cuda:0' if GPU_AVAILABLE else 'cpu',\n",
    "            'random_state': SEED,\n",
    "            'n_jobs': -1,\n",
    "            'eval_metric': 'logloss',\n",
    "            'use_label_encoder': False\n",
    "        }\n",
    "        \n",
    "        models.append(make_pipeline(\n",
    "            SimpleImputer(),\n",
    "            StratifiedSubsetClassifier(\n",
    "                XGBClassifier(**xgb_params), int(base_n_samples / 1.5)  # ~400K samples\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "        # =============================================================================\n",
    "        # MODEL 4: CatBoost - Configuration 1 (400 iterations)\n",
    "        # =============================================================================\n",
    "        if CATBOOST_AVAILABLE:\n",
    "            catboost_params_1 = {\n",
    "                'iterations': 400,              # Increased from 180\n",
    "                'learning_rate': 0.1,           # Increased from 0.08\n",
    "                'depth': 6,\n",
    "                'verbose': False,\n",
    "                'allow_writing_files': False,\n",
    "                'random_seed': SEED,\n",
    "            }\n",
    "            if GPU_AVAILABLE:\n",
    "                catboost_params_1['task_type'] = 'GPU'\n",
    "                catboost_params_1['devices'] = '0'\n",
    "            \n",
    "            models.append(make_pipeline(\n",
    "                SimpleImputer(),\n",
    "                StratifiedSubsetClassifier(\n",
    "                    CatBoostClassifier(**catboost_params_1), base_n_samples  # 600K samples\n",
    "                )\n",
    "            ))\n",
    "        \n",
    "        # =============================================================================\n",
    "        # MODEL 5: CatBoost - Configuration 2 (300 iterations)\n",
    "        # =============================================================================\n",
    "        if CATBOOST_AVAILABLE:\n",
    "            catboost_params_2 = {\n",
    "                'iterations': 300,\n",
    "                'learning_rate': 0.1,\n",
    "                'depth': 6,\n",
    "                'verbose': False,\n",
    "                'allow_writing_files': False,\n",
    "                'random_seed': SEED+1,\n",
    "            }\n",
    "            if GPU_AVAILABLE:\n",
    "                catboost_params_2['task_type'] = 'GPU'\n",
    "                catboost_params_2['devices'] = '0'\n",
    "            \n",
    "            models.append(make_pipeline(\n",
    "                SimpleImputer(),\n",
    "                StratifiedSubsetClassifier(\n",
    "                    CatBoostClassifier(**catboost_params_2), base_n_samples  # 600K samples\n",
    "                )\n",
    "            ))\n",
    "        \n",
    "        # =============================================================================\n",
    "        # OPTIMIZED MODEL WEIGHTS\n",
    "        # Based on analysis: LightGBM and XGBoost perform best, CatBoost adds diversity\n",
    "        # =============================================================================\n",
    "        if CATBOOST_AVAILABLE:\n",
    "            # 5 models: 2 LGBM + 1 XGB + 2 CatBoost\n",
    "            model_weights = [0.25, 0.20, 0.30, 0.15, 0.10]\n",
    "        else:\n",
    "            # 3 models: 2 LGBM + 1 XGB\n",
    "            model_weights = [0.35, 0.30, 0.35]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  ✓ Ensemble configured: {len(models)} models\")\n",
    "            print(f\"    Weights: {model_weights}\")\n",
    "            print(f\"    Sample sizes: {[f'{int(base_n_samples/1.3):,}', f'{int(base_n_samples/2):,}', f'{int(base_n_samples/1.5):,}', f'{base_n_samples:,}', f'{base_n_samples:,}'][:len(models)]}\")\n",
    "        \n",
    "        # ---------------------------\n",
    "        # ---------------------------\n",
    "        # Predict single-mouse actions\n",
    "        if len(single_mouse_list) > 0:\n",
    "            # Concatenate all batches\n",
    "            single_mouse = pd.concat(single_mouse_list)\n",
    "            single_mouse_label = pd.concat(single_mouse_label_list)\n",
    "            single_mouse_meta = pd.concat(single_mouse_meta_list)\n",
    "            del single_mouse_list, single_mouse_label_list, single_mouse_meta_list\n",
    "            assert len(single_mouse) == len(single_mouse_label)\n",
    "            assert len(single_mouse) == len(single_mouse_meta)\n",
    "            \n",
    "            # Get FPS for feature transformation\n",
    "            fps = single_mouse_meta['fps'].iloc[0] if 'fps' in single_mouse_meta.columns else 30.0\n",
    "            \n",
    "            # Transform with FPS awareness\n",
    "            X_tr = transform_single(single_mouse, body_parts_tracked, fps)\n",
    "            del single_mouse\n",
    "            print(f\"{X_tr.shape=}\")\n",
    "    \n",
    "            if validate_or_submit == 'validate':\n",
    "                cross_validate_classifier(models, X_tr, single_mouse_label, single_mouse_meta)\n",
    "            else:\n",
    "                submit(body_parts_tracked_str, 'single', models, model_weights, X_tr, single_mouse_label, single_mouse_meta)\n",
    "            del X_tr\n",
    "            gc.collect()\n",
    "                \n",
    "        # Predict mouse-pair actions\n",
    "        if len(mouse_pair_list) > 0:\n",
    "            # Concatenate all batches\n",
    "            mouse_pair = pd.concat(mouse_pair_list)\n",
    "            mouse_pair_label = pd.concat(mouse_pair_label_list)\n",
    "            mouse_pair_meta = pd.concat(mouse_pair_meta_list)\n",
    "            del mouse_pair_list, mouse_pair_label_list, mouse_pair_meta_list\n",
    "            assert len(mouse_pair) == len(mouse_pair_label)\n",
    "            assert len(mouse_pair) == len(mouse_pair_meta)\n",
    "        \n",
    "            # Get FPS for feature transformation\n",
    "            fps = mouse_pair_meta['fps'].iloc[0] if 'fps' in mouse_pair_meta.columns else 30.0\n",
    "            \n",
    "            # Transform with FPS awareness\n",
    "            X_tr = transform_pair(mouse_pair, body_parts_tracked, fps)\n",
    "            del mouse_pair\n",
    "            print(f\"{X_tr.shape=}\")\n",
    "    \n",
    "            if validate_or_submit == 'validate':\n",
    "                cross_validate_classifier(models, X_tr, mouse_pair_label, mouse_pair_meta)\n",
    "            else:\n",
    "                submit(body_parts_tracked_str, 'pair', models, model_weights, X_tr, mouse_pair_label, mouse_pair_meta)\n",
    "            del X_tr\n",
    "            gc.collect()\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f'***Exception*** {e}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32ab3787",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:48:03.680144Z",
     "iopub.status.busy": "2025-12-12T17:48:03.679689Z",
     "iopub.status.idle": "2025-12-12T17:48:03.695747Z",
     "shell.execute_reply": "2025-12-12T17:48:03.695113Z"
    },
    "papermill": {
     "duration": 0.027982,
     "end_time": "2025-12-12T17:48:03.697015",
     "exception": false,
     "start_time": "2025-12-12T17:48:03.669033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def robustify(submission, dataset, traintest, traintest_directory=None):\n",
    "    \"\"\"Ensure that the submission conforms to the three rules\"\"\"\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n",
    "\n",
    "    # Rule 1: Ensure that start_frame >= stop_frame\n",
    "    old_submission = submission.copy()\n",
    "    submission = submission[submission.start_frame < submission.stop_frame]\n",
    "    if len(submission) != len(old_submission):\n",
    "        print(\"ERROR: Dropped frames with start >= stop\")\n",
    "    \n",
    "    # Rule 2: Avoid multiple predictions for the same frame from one agent/target pair\n",
    "    old_submission = submission.copy()\n",
    "    group_list = []\n",
    "    for _, group in submission.groupby(['video_id', 'agent_id', 'target_id']):\n",
    "        group = group.sort_values('start_frame')\n",
    "        mask = np.ones(len(group), dtype=bool)\n",
    "        last_stop_frame = 0\n",
    "        for i, (_, row) in enumerate(group.iterrows()):\n",
    "            if row['start_frame'] < last_stop_frame:\n",
    "                mask[i] = False\n",
    "            else:\n",
    "                last_stop_frame = row['stop_frame']\n",
    "        group_list.append(group[mask])\n",
    "    submission = pd.concat(group_list)\n",
    "    if len(submission) != len(old_submission):\n",
    "        print(\"ERROR: Dropped duplicate frames\")\n",
    "\n",
    "    # Rule 3: Submit something for every video\n",
    "    # Fill missing videos as in https://www.kaggle.com/code/ambrosm/mabe-validated-baseline-without-machine-learning\n",
    "    s_list = []\n",
    "    for idx, row in dataset.iterrows():\n",
    "        lab_id = row['lab_id']\n",
    "        if lab_id.startswith('MABe22'):\n",
    "            continue\n",
    "        video_id = row['video_id']\n",
    "        if (submission.video_id == video_id).any():\n",
    "            continue\n",
    "\n",
    "        if verbose: print(f\"Video {video_id} has no predictions.\")\n",
    "        \n",
    "        # Load video\n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path)\n",
    "    \n",
    "        # Determine the behaviors of this video\n",
    "        # Determine the behaviors of this video\n",
    "        val = row['behaviors_labeled']\n",
    "\n",
    "        # 1. Nếu NaN -> không có label hành vi -> bỏ qua rule 3 cho video này\n",
    "        if pd.isna(val):\n",
    "            if verbose:\n",
    "                print(f\"WARN: behaviors_labeled is NaN for video {video_id}, skip filling.\")\n",
    "            continue\n",
    "\n",
    "        # 2. Nếu là string -> parse bằng literal_eval (an toàn hơn eval)\n",
    "        if isinstance(val, str):\n",
    "            try:\n",
    "                vid_behaviors = ast.literal_eval(val)\n",
    "            except Exception as e:\n",
    "                print(f\"WARN: could not parse behaviors_labeled for video {video_id}: {e}\")\n",
    "                continue\n",
    "\n",
    "        # 3. Nếu đã là list/tuple -> dùng luôn\n",
    "        elif isinstance(val, (list, tuple, np.ndarray)):\n",
    "            vid_behaviors = val\n",
    "\n",
    "        # 4. Kiểu khác -> bỏ qua\n",
    "        else:\n",
    "            print(f\"WARN: unexpected type for behaviors_labeled in video {video_id}: {type(val)}\")\n",
    "            continue\n",
    "\n",
    "        # Phần còn lại giữ nguyên\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
    "    \n",
    "        # Determine start_frame and stop_frame\n",
    "        start_frame = vid.video_frame.min()\n",
    "        stop_frame = vid.video_frame.max() + 1\n",
    "    \n",
    "        # Predict all possible actions as often as possible\n",
    "        for (agent, target), actions in vid_behaviors.groupby(['agent', 'target']):\n",
    "            batch_length = int(np.ceil((stop_frame - start_frame) / len(actions)))\n",
    "            for i, (_, action_row) in enumerate(actions.iterrows()):\n",
    "                batch_start = start_frame + i * batch_length\n",
    "                batch_stop = min(batch_start + batch_length, stop_frame)\n",
    "                s_list.append((video_id, agent, target, action_row['action'], batch_start, batch_stop))\n",
    "\n",
    "    if len(s_list) > 0:\n",
    "        submission = pd.concat([\n",
    "            submission,\n",
    "            pd.DataFrame(s_list, columns=['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'])\n",
    "        ])\n",
    "        print(\"ERROR: Filled empty videos\")\n",
    "\n",
    "    submission = submission.reset_index(drop=True)\n",
    "    return submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62fa72db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:48:03.713161Z",
     "iopub.status.busy": "2025-12-12T17:48:03.712923Z",
     "iopub.status.idle": "2025-12-12T17:48:03.716996Z",
     "shell.execute_reply": "2025-12-12T17:48:03.716320Z"
    },
    "papermill": {
     "duration": 0.013663,
     "end_time": "2025-12-12T17:48:03.718111",
     "exception": false,
     "start_time": "2025-12-12T17:48:03.704448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if validate_or_submit == 'validate':\n",
    "    # Score the oof predictions with the competition scoring function\n",
    "    submission = pd.concat(submission_list)\n",
    "    submission_robust = robustify(submission, train, 'train')\n",
    "    print(f\"# OOF score with competition metric: {score(solution, submission_robust, ''):.4f}\")\n",
    "\n",
    "    f1_df = pd.DataFrame(f1_list, columns=['body_parts_tracked_str', 'action', 'binary F1 score'])\n",
    "    print(f\"# Average of {len(f1_df)} binary F1 scores {f1_df['binary F1 score'].mean():.4f}\")\n",
    "    # with pd.option_context('display.max_rows', 500):\n",
    "    #     display(f1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "577c8f72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-12T17:48:03.734284Z",
     "iopub.status.busy": "2025-12-12T17:48:03.734083Z",
     "iopub.status.idle": "2025-12-12T17:48:04.158717Z",
     "shell.execute_reply": "2025-12-12T17:48:04.157814Z"
    },
    "papermill": {
     "duration": 0.434835,
     "end_time": "2025-12-12T17:48:04.160164",
     "exception": false,
     "start_time": "2025-12-12T17:48:03.725329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_id,video_id,agent_id,target_id,action,start_frame,stop_frame\r\n",
      "0,438887472,mouse1,mouse3,approach,2286,2291\r\n",
      "1,438887472,mouse1,mouse4,attack,1417,1419\r\n",
      "2,438887472,mouse1,mouse4,attack,1425,1442\r\n",
      "3,438887472,mouse1,mouse4,attack,1452,1486\r\n",
      "4,438887472,mouse1,mouse4,attack,1495,1503\r\n",
      "5,438887472,mouse1,mouse4,attack,1505,1524\r\n",
      "6,438887472,mouse1,mouse4,attack,1534,1537\r\n",
      "7,438887472,mouse1,mouse4,submit,2381,2389\r\n",
      "8,438887472,mouse1,mouse4,avoid,2564,2581\r\n"
     ]
    }
   ],
   "source": [
    "if validate_or_submit != 'validate':\n",
    "    if len(submission_list) > 0:\n",
    "        submission = pd.concat(submission_list)\n",
    "    else:\n",
    "        submission = pd.DataFrame(\n",
    "            dict(\n",
    "                video_id=438887472,\n",
    "                agent_id='mouse1',\n",
    "                target_id='self',\n",
    "                action='rear',\n",
    "                start_frame=278,\n",
    "                stop_frame=500\n",
    "            ), index=[44])\n",
    "    if validate_or_submit == 'submit':\n",
    "        submission_robust = robustify(submission, test, 'test')\n",
    "    else:\n",
    "        submission_robust = robustify(submission, stresstest, 'stresstest', 'stresstest_tracking')\n",
    "    submission_robust.index.name = 'row_id'\n",
    "    submission_robust.to_csv('submission.csv')\n",
    "    !head submission.csv"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13874099,
     "sourceId": 59156,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8918.925392,
   "end_time": "2025-12-12T17:48:07.317564",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-12T15:19:28.392172",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
