{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fb51c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:40:57.697554Z",
     "iopub.status.busy": "2025-12-13T17:40:57.697232Z",
     "iopub.status.idle": "2025-12-13T17:41:20.380881Z",
     "shell.execute_reply": "2025-12-13T17:41:20.379525Z"
    },
    "papermill": {
     "duration": 22.691344,
     "end_time": "2025-12-13T17:41:20.382284",
     "exception": false,
     "start_time": "2025-12-13T17:40:57.690940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ PyTorch GPU Available: Tesla T4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n",
      "1 warning generated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LightGBM GPU support detected\n",
      "\n",
      "==================================================\n",
      "GPU Configuration:\n",
      "  - XGBoost will use: GPU (cuda:0)\n",
      "  - LightGBM will use: GPU\n",
      "  - CatBoost will use: GPU\n",
      "==================================================\n",
      "\n",
      "FPS-Aware mode enabled with:\n",
      "  - SEED: 1234\n",
      "  - Smoothing window: 5 frames @ 30 FPS\n",
      "  - Min duration: 0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1 warning generated.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL: Imports (FPS-Aware Version from v4)\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange, tqdm\n",
    "import itertools\n",
    "import warnings\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import lightgbm\n",
    "import ast\n",
    "import gc\n",
    "import traceback\n",
    "from collections import defaultdict\n",
    "import polars as pl  # Required for scoring functions\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.base import ClassifierMixin, BaseEstimator, clone\n",
    "from sklearn.model_selection import cross_val_predict, GroupKFold, train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, module='pandas.core.arraylike')\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, module='pandas.core.computation')\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='xgboost.core')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "validate_or_submit = 'submit' # 'validate' or 'submit' or 'stresstest'\n",
    "verbose = True\n",
    "\n",
    "# FPS-Aware Configuration Parameters (from Reference Notebook v4)\n",
    "SMOOTHING_WINDOW_FRAMES_AT_30FPS = 5  # Base smoothing window (scales with FPS)\n",
    "MIN_DURATION_SECONDS = 0.1  # Minimum event duration in seconds (scales with FPS)\n",
    "\n",
    "# Seed for reproducibility\n",
    "SEED = 1234\n",
    "import os, random\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Try importing CatBoost (optional)\n",
    "try:\n",
    "    from catboost import CatBoostClassifier\n",
    "    CATBOOST_AVAILABLE = True\n",
    "except:\n",
    "    CATBOOST_AVAILABLE = False\n",
    "    print(\"CatBoost not available\")\n",
    "\n",
    "# Check GPU availability\n",
    "GPU_AVAILABLE = False\n",
    "LGBM_GPU_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        GPU_AVAILABLE = True\n",
    "        print(f\"✓ PyTorch GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "except:\n",
    "    print(\"✗ PyTorch GPU not available\")\n",
    "\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    test_data = lgb.Dataset(np.random.rand(100, 10), label=np.random.randint(0, 2, 100))\n",
    "    test_params = {'device': 'gpu', 'gpu_platform_id': 0, 'gpu_device_id': 0, 'verbose': -1}\n",
    "    lgb.train(test_params, test_data, num_boost_round=1)\n",
    "    LGBM_GPU_AVAILABLE = True\n",
    "    print(\"✓ LightGBM GPU support detected\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ LightGBM GPU not available: {str(e)[:80]}\")\n",
    "    LGBM_GPU_AVAILABLE = False\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"GPU Configuration:\")\n",
    "print(f\"  - XGBoost will use: {'GPU (cuda:0)' if GPU_AVAILABLE else 'CPU (hist)'}\")\n",
    "print(f\"  - LightGBM will use: {'GPU' if LGBM_GPU_AVAILABLE else 'CPU'}\")\n",
    "print(f\"  - CatBoost will use: {'GPU' if GPU_AVAILABLE and CATBOOST_AVAILABLE else 'CPU'}\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "print(\"FPS-Aware mode enabled with:\")\n",
    "print(f\"  - SEED: {SEED}\")\n",
    "print(f\"  - Smoothing window: {SMOOTHING_WINDOW_FRAMES_AT_30FPS} frames @ 30 FPS\")\n",
    "print(f\"  - Min duration: {MIN_DURATION_SECONDS}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1635ce0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:20.394283Z",
     "iopub.status.busy": "2025-12-13T17:41:20.393741Z",
     "iopub.status.idle": "2025-12-13T17:41:20.405001Z",
     "shell.execute_reply": "2025-12-13T17:41:20.404473Z"
    },
    "papermill": {
     "duration": 0.01812,
     "end_time": "2025-12-13T17:41:20.406093",
     "exception": false,
     "start_time": "2025-12-13T17:41:20.387973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: StratifiedSubsetClassifier (Replace TrainOnSubsetClassifier cell)\n",
    "# =============================================================================\n",
    "\n",
    "class StratifiedSubsetClassifier(ClassifierMixin, BaseEstimator):\n",
    "    \"\"\"Enhanced classifier with stratified sampling for balanced class distribution\n",
    "    \n",
    "    Key improvements over TrainOnSubsetClassifier:\n",
    "    - Uses StratifiedShuffleSplit to maintain class balance\n",
    "    - Better edge case handling (single class, GPU fallback)\n",
    "    - Memory efficient with float32\n",
    "    \"\"\"\n",
    "    def __init__(self, estimator, n_samples=50_000):\n",
    "        self.estimator = estimator\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def _to_numpy(self, X):\n",
    "        \"\"\"Convert to numpy float32 for memory efficiency\"\"\"\n",
    "        try:\n",
    "            return X.to_numpy(np.float32, copy=False)\n",
    "        except AttributeError:\n",
    "            return np.asarray(X, dtype=np.float32)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        Xn = self._to_numpy(X)\n",
    "        y = np.asarray(y).ravel()\n",
    "\n",
    "        # If n_samples is None → fit on full data\n",
    "        if self.n_samples is None or len(Xn) <= int(self.n_samples):\n",
    "            self.estimator.fit(Xn, y)\n",
    "        else:\n",
    "            # Stratified sampling to maintain class balance\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, train_size=int(self.n_samples), random_state=SEED)\n",
    "            try:\n",
    "                idx, _ = next(sss.split(np.zeros_like(y), y))\n",
    "                self.estimator.fit(Xn[idx], y[idx])\n",
    "            except Exception as e:\n",
    "                # Fallback to simple subsampling if stratification fails\n",
    "                print(f\"  Stratification failed, using step sampling: {str(e)[:50]}\")\n",
    "                step = max(len(Xn) // int(self.n_samples), 1)\n",
    "                self.estimator.fit(Xn[::step], y[::step])\n",
    "\n",
    "        try:\n",
    "            self.classes_ = np.asarray(self.estimator.classes_)\n",
    "        except Exception:\n",
    "            self.classes_ = np.unique(y)\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        Xn = self._to_numpy(X)\n",
    "        try:\n",
    "            P = self.estimator.predict_proba(Xn)\n",
    "        except Exception:\n",
    "            # Handle edge cases\n",
    "            if len(self.classes_) == 1:\n",
    "                n = len(Xn)\n",
    "                c = int(self.classes_[0])\n",
    "                if c == 1:\n",
    "                    return np.column_stack([np.zeros(n, dtype=np.float32), np.ones(n, dtype=np.float32)])\n",
    "                else:\n",
    "                    return np.column_stack([np.ones(n, dtype=np.float32), np.zeros(n, dtype=np.float32)])\n",
    "            return np.full((len(Xn), 2), 0.5, dtype=np.float32)\n",
    "\n",
    "        P = np.asarray(P, dtype=np.float32)\n",
    "        if P.ndim == 1:\n",
    "            P1 = P.astype(np.float32)\n",
    "            return np.column_stack([1.0 - P1, P1])\n",
    "        if P.shape[1] == 1 and len(self.classes_) == 2:\n",
    "            P1 = P[:, 0].astype(np.float32)\n",
    "            return np.column_stack([1.0 - P1, P1])\n",
    "        return P\n",
    "\n",
    "    def predict(self, X):\n",
    "        Xn = self._to_numpy(X)\n",
    "        try:\n",
    "            return self.estimator.predict(Xn)\n",
    "        except Exception:\n",
    "            return np.argmax(self.predict_proba(Xn), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d2ea9a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:20.415350Z",
     "iopub.status.busy": "2025-12-13T17:41:20.415137Z",
     "iopub.status.idle": "2025-12-13T17:41:20.431955Z",
     "shell.execute_reply": "2025-12-13T17:41:20.431256Z"
    },
    "papermill": {
     "duration": 0.022743,
     "end_time": "2025-12-13T17:41:20.432968",
     "exception": false,
     "start_time": "2025-12-13T17:41:20.410225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"F Beta customized for the data format of the MABe challenge.\"\"\"\n",
    "\n",
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "class HostVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1) -> float:\n",
    "    label_frames: defaultdict[str, set[int]] = defaultdict(set) # key is video/agent/target/action from solution\n",
    "    prediction_frames: defaultdict[str, set[int]] = defaultdict(set) # key is video/agent/target/action from submission\n",
    "\n",
    "    for row in lab_solution.to_dicts():\n",
    "        label_frames[row['label_key']].update(range(row['start_frame'], row['stop_frame']))\n",
    "\n",
    "    for video in lab_solution['video_id'].unique():\n",
    "        active_labels: str = lab_solution.filter(pl.col('video_id') == video)['behaviors_labeled'].first()  # ty: ignore\n",
    "        active_labels: set[str] = set(json.loads(active_labels)) # set of agent,target,action from solution\n",
    "        predicted_mouse_pairs: defaultdict[str, set[int]] = defaultdict(set) # key is agent,target from submission\n",
    "\n",
    "        for row in lab_submission.filter(pl.col('video_id') == video).to_dicts(): # every submission row is converted to a dict\n",
    "            # Since the labels are sparse, we can't evaluate prediction keys not in the active labels.\n",
    "            if ','.join([str(row['agent_id']), str(row['target_id']), row['action']]) not in active_labels:\n",
    "                # print(f'ignoring {video}', ','.join([str(row['agent_id']), str(row['target_id']), row['action']]), active_labels)\n",
    "                continue # these submission rows are ignored\n",
    "           \n",
    "            new_frames = set(range(row['start_frame'], row['stop_frame']))\n",
    "            # Ignore truly redundant predictions.\n",
    "            new_frames = new_frames.difference(prediction_frames[row['prediction_key']])\n",
    "            prediction_pair = ','.join([str(row['agent_id']), str(row['target_id'])])\n",
    "            if predicted_mouse_pairs[prediction_pair].intersection(new_frames):\n",
    "                # A single agent can have multiple targets per frame (ex: evading all other mice) but only one action per target per frame.\n",
    "                raise HostVisibleError('Multiple predictions for the same frame from one agent/target pair')\n",
    "            prediction_frames[row['prediction_key']].update(new_frames)\n",
    "            predicted_mouse_pairs[prediction_pair].update(new_frames)\n",
    "\n",
    "    tps = defaultdict(int) # key is action\n",
    "    fns = defaultdict(int) # key is action\n",
    "    fps = defaultdict(int) # key is action\n",
    "    for key, pred_frames in prediction_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        matched_label_frames = label_frames[key]\n",
    "        tps[action] += len(pred_frames.intersection(matched_label_frames))\n",
    "        fns[action] += len(matched_label_frames.difference(pred_frames))\n",
    "        fps[action] += len(pred_frames.difference(matched_label_frames))\n",
    "\n",
    "    distinct_actions = set()\n",
    "    for key, frames in label_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        distinct_actions.add(action)\n",
    "        if key not in prediction_frames:\n",
    "            fns[action] += len(frames)\n",
    "\n",
    "    action_f1s = []\n",
    "    for action in distinct_actions:\n",
    "        # print(f\"{tps[action]:8} {fns[action]:8} {fps[action]:8}\")\n",
    "        if tps[action] + fns[action] + fps[action] == 0:\n",
    "            action_f1s.append(0)\n",
    "        else:\n",
    "            action_f1s.append((1 + beta**2) * tps[action] / ((1 + beta**2) * tps[action] + beta**2 * fns[action] + fps[action]))\n",
    "    return sum(action_f1s) / len(action_f1s)\n",
    "\n",
    "\n",
    "def mouse_fbeta(solution: pd.DataFrame, submission: pd.DataFrame, beta: float = 1) -> float:\n",
    "    \"\"\"\n",
    "    Doctests:\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10},\n",
    "    ... ])\n",
    "    >>> mouse_fbeta(solution, submission)\n",
    "    1.0\n",
    "\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 0, 'stop_frame': 10}, # Wrong action\n",
    "    ... ])\n",
    "    >>> mouse_fbeta(solution, submission)\n",
    "    0.0\n",
    "\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 15, 'stop_frame': 24, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9},\n",
    "    ... ])\n",
    "    >>> \"%.12f\" % mouse_fbeta(solution, submission)\n",
    "    '0.500000000000'\n",
    "\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 15, 'stop_frame': 24, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 345, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9, 'lab_id': 2, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 345, 'agent_id': 1, 'target_id': 2, 'action': 'mount', 'start_frame': 15, 'stop_frame': 24, 'lab_id': 2, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 123, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 9},\n",
    "    ... ])\n",
    "    >>> \"%.12f\" % mouse_fbeta(solution, submission)\n",
    "    '0.250000000000'\n",
    "\n",
    "    >>> # Overlapping solution events, one prediction matching both.\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 10, 'stop_frame': 20, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 20},\n",
    "    ... ])\n",
    "    >>> mouse_fbeta(solution, submission)\n",
    "    1.0\n",
    "\n",
    "    >>> solution = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 10, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 30, 'stop_frame': 40, 'lab_id': 1, 'behaviors_labeled': '[\"1,2,attack\"]'},\n",
    "    ... ])\n",
    "    >>> submission = pd.DataFrame([\n",
    "    ...     {'video_id': 1, 'agent_id': 1, 'target_id': 2, 'action': 'attack', 'start_frame': 0, 'stop_frame': 40},\n",
    "    ... ])\n",
    "    >>> mouse_fbeta(solution, submission)\n",
    "    0.6666666666666666\n",
    "    \"\"\"\n",
    "    if len(solution) == 0 or len(submission) == 0:\n",
    "        raise ValueError('Missing solution or submission data')\n",
    "\n",
    "    expected_cols = ['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']\n",
    "\n",
    "    for col in expected_cols:\n",
    "        if col not in solution.columns:\n",
    "            raise ValueError(f'Solution is missing column {col}')\n",
    "        if col not in submission.columns:\n",
    "            raise ValueError(f'Submission is missing column {col}')\n",
    "\n",
    "    solution: pl.DataFrame = pl.DataFrame(solution)\n",
    "    submission: pl.DataFrame = pl.DataFrame(submission)\n",
    "    assert (solution['start_frame'] <= solution['stop_frame']).all()\n",
    "    assert (submission['start_frame'] <= submission['stop_frame']).all()\n",
    "    solution_videos = set(solution['video_id'].unique())\n",
    "    # Need to align based on video IDs as we can't rely on the row IDs for handling public/private splits.\n",
    "    submission = submission.filter(pl.col('video_id').is_in(solution_videos))\n",
    "\n",
    "    solution = solution.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('label_key'),\n",
    "    )\n",
    "    submission = submission.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('prediction_key'),\n",
    "    )\n",
    "\n",
    "    lab_scores = []\n",
    "    for lab in solution['lab_id'].unique():\n",
    "        lab_solution = solution.filter(pl.col('lab_id') == lab).clone()\n",
    "        lab_videos = set(lab_solution['video_id'].unique())\n",
    "        lab_submission = submission.filter(pl.col('video_id').is_in(lab_videos)).clone()\n",
    "        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n",
    "\n",
    "    return sum(lab_scores) / len(lab_scores)\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, beta: float = 1) -> float:\n",
    "    \"\"\"\n",
    "    F1 score for the MABe Challenge\n",
    "    \"\"\"\n",
    "    solution = solution.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    submission = submission.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    return mouse_fbeta(solution, submission, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57171f8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:20.442128Z",
     "iopub.status.busy": "2025-12-13T17:41:20.441894Z",
     "iopub.status.idle": "2025-12-13T17:41:20.609365Z",
     "shell.execute_reply": "2025-12-13T17:41:20.608765Z"
    },
    "papermill": {
     "duration": 0.17353,
     "end_time": "2025-12-13T17:41:20.610621",
     "exception": false,
     "start_time": "2025-12-13T17:41:20.437091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/train.csv')\n",
    "train['n_mice'] = 4 - train[['mouse1_strain', 'mouse2_strain', 'mouse3_strain', 'mouse4_strain']].isna().sum(axis=1)\n",
    "train_without_mabe22 = train.query(\"~ lab_id.str.startswith('MABe22_')\")\n",
    "\n",
    "test = pd.read_csv('/kaggle/input/MABe-mouse-behavior-detection/test.csv')\n",
    "\n",
    "# labs = list(np.unique(train.lab_id))\n",
    "\n",
    "body_parts_tracked_list = list(np.unique(train.body_parts_tracked))\n",
    "\n",
    "# behaviors = list(train.behaviors_labeled.drop_duplicates().dropna())\n",
    "# behaviors = sorted(list({b.replace(\"'\", \"\") for bb in behaviors for b in json.loads(bb)}))\n",
    "# behaviors = [b.split(',') for b in behaviors]\n",
    "# behaviors = pd.DataFrame(behaviors, columns=['agent', 'target', 'action'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67ab936",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:20.620652Z",
     "iopub.status.busy": "2025-12-13T17:41:20.620428Z",
     "iopub.status.idle": "2025-12-13T17:41:20.635476Z",
     "shell.execute_reply": "2025-12-13T17:41:20.634943Z"
    },
    "papermill": {
     "duration": 0.021502,
     "end_time": "2025-12-13T17:41:20.636625",
     "exception": false,
     "start_time": "2025-12-13T17:41:20.615123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: HMM & Viterbi Functions (NEW)\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "def estimate_transition_matrix_fast(train_df, all_actions):\n",
    "    \"\"\"Tính ma trận chuyển đổi dựa trên cột behaviors_labeled của train.csv\"\"\"\n",
    "    n_states = len(all_actions)\n",
    "    act2idx = {act: i for i, act in enumerate(all_actions)}\n",
    "    transitions = np.zeros((n_states, n_states))\n",
    "    \n",
    "    print(\"Computing transition matrix from metadata...\")\n",
    "    for _, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
    "        if pd.isna(row['behaviors_labeled']): continue\n",
    "        \n",
    "        # Parse behaviors\n",
    "        try:\n",
    "            behaviors = ast.literal_eval(row['behaviors_labeled']) if isinstance(row['behaviors_labeled'], str) else row['behaviors_labeled']\n",
    "        except: continue\n",
    "            \n",
    "        # Parse thành DataFrame\n",
    "        behaviors = sorted(list({b.replace(\"'\", \"\") for b in behaviors}))\n",
    "        behaviors = [b.split(',') for b in behaviors]\n",
    "        if not behaviors: continue\n",
    "        \n",
    "        # Giả lập timeline cho từng cặp agent-target\n",
    "        # Vì ta không load file parquet nên ta dùng start/stop frame để ước lượng\n",
    "        # Lưu ý: Đây là ước lượng gần đúng nhưng đủ tốt và rất nhanh\n",
    "        b_df = pd.DataFrame(behaviors, columns=['agent', 'target', 'action'])\n",
    "        \n",
    "        # Gom nhóm theo agent-target\n",
    "        for _, group in b_df.groupby(['agent', 'target']):\n",
    "            # Sắp xếp theo thời gian\n",
    "            # (Dữ liệu gốc behavior string không có frame, nhưng ta giả định\n",
    "            # hành vi background xen kẽ giữa các hành vi)\n",
    "            \n",
    "            # Với cách tính nhanh này, ta ưu tiên đếm sự chuyển đổi giữa:\n",
    "            # Action A -> Background -> Action B hoặc Action A -> Action B\n",
    "            # Ta giả định Background luôn xuất hiện giữa các hành vi không liên tiếp\n",
    "            \n",
    "            last_action_idx = act2idx['background']\n",
    "            \n",
    "            for action in group['action']:\n",
    "                if action not in act2idx: continue\n",
    "                curr_idx = act2idx[action]\n",
    "                \n",
    "                # Background -> Action\n",
    "                transitions[last_action_idx, curr_idx] += 1\n",
    "                # Action -> Action (giả sử giữ trạng thái này một lúc - self loop)\n",
    "                transitions[curr_idx, curr_idx] += 100 # Weight cho việc giữ trạng thái\n",
    "                # Action -> Background\n",
    "                transitions[curr_idx, act2idx['background']] += 1\n",
    "                \n",
    "                last_action_idx = act2idx['background']\n",
    "\n",
    "    # Normalize và Log\n",
    "    # Tăng trọng số đường chéo (self-transition) để hành vi mượt hơn\n",
    "    np.fill_diagonal(transitions, transitions.diagonal() + 1000) \n",
    "    \n",
    "    epsilon = 1e-6\n",
    "    transitions = transitions + epsilon\n",
    "    trans_prob = transitions / transitions.sum(axis=1, keepdims=True)\n",
    "    return np.log(trans_prob)\n",
    "\n",
    "def viterbi_decode(predictions, trans_log_prob):\n",
    "    \"\"\"Viterbi algorithm in Log-space\"\"\"\n",
    "    T, N = predictions.shape\n",
    "    start_log_prob = np.zeros(N) - np.log(N) # Uniform start\n",
    "    \n",
    "    V = np.zeros((T, N))\n",
    "    backpointer = np.zeros((T, N), dtype=int)\n",
    "    \n",
    "    # Init\n",
    "    V[0] = start_log_prob + predictions[0]\n",
    "    \n",
    "    # Forward\n",
    "    for t in range(1, T):\n",
    "        score_trans = V[t-1].reshape(-1, 1) + trans_log_prob\n",
    "        V[t] = np.max(score_trans, axis=0) + predictions[t]\n",
    "        backpointer[t] = np.argmax(score_trans, axis=0)\n",
    "        \n",
    "    # Backward\n",
    "    path = np.zeros(T, dtype=int)\n",
    "    path[-1] = np.argmax(V[-1])\n",
    "    for t in range(T-2, -1, -1):\n",
    "        path[t] = backpointer[t+1, path[t+1]]\n",
    "        \n",
    "    return path\n",
    "\n",
    "def predict_multiclass_hmm(pred, meta, trans_log_prob, all_actions_list):\n",
    "    \"\"\"\n",
    "    HMM Tuned for High Recall (Đã chỉnh sửa để tăng độ nhạy)\n",
    "    \"\"\"\n",
    "    # 1. Chuẩn bị xác suất\n",
    "    full_probs = pd.DataFrame(index=pred.index)\n",
    "    \n",
    "    # Copy xác suất các hành vi hiện có\n",
    "    for col in all_actions_list:\n",
    "        if col in pred.columns:\n",
    "            full_probs[col] = pred[col]\n",
    "        elif col == 'background':\n",
    "            full_probs['background'] = 0.5\n",
    "        else:\n",
    "            full_probs[col] = 1e-6\n",
    "\n",
    "    # --- [SỬA ĐỔI QUAN TRỌNG 1: Xử lý Background] ---\n",
    "    if 'background' in full_probs.columns:\n",
    "        # Tính background dựa trên phần dư\n",
    "        max_p = pred.max(axis=1).fillna(0)\n",
    "        \n",
    "        # CŨ: full_probs['background'] = 1.0 - max_p\n",
    "        # MỚI: Giảm xác suất background xuống để ưu tiên bắt hành vi (Recall)\n",
    "        # Chúng ta nhân với 0.3 để \"dìm\" background xuống\n",
    "        full_probs['background'] = (1.0 - max_p) * 0.3\n",
    "        \n",
    "        # Đảm bảo không quá nhỏ để log không lỗi\n",
    "        full_probs['background'] = full_probs['background'].clip(0.001, 0.999)\n",
    "        \n",
    "    # Chuẩn hóa lại tổng = 1\n",
    "    full_probs = full_probs.div(full_probs.sum(axis=1), axis=0)\n",
    "    \n",
    "    # Chuyển sang Log space\n",
    "    emission_log = np.log(full_probs[all_actions_list].values + 1e-9)\n",
    "    \n",
    "    # --- [SỬA ĐỔI QUAN TRỌNG 2: Tăng trọng số Emission] ---\n",
    "    # Tăng từ 2.0 -> 15.0 để bám sát dự đoán của XGBoost/LGBM hơn\n",
    "    # Nếu vẫn thấp, có thể tăng lên 20.0\n",
    "    weight_emission = 15.0 \n",
    "    \n",
    "    # Chạy Viterbi\n",
    "    path_indices = viterbi_decode(emission_log * weight_emission, trans_log_prob)\n",
    "    \n",
    "    # Convert indices sang tên hành vi\n",
    "    idx2act = {i: act for i, act in enumerate(all_actions_list)}\n",
    "    decoded = [idx2act[i] for i in path_indices]\n",
    "    \n",
    "    ama = pd.Series(decoded, index=meta.video_frame)\n",
    "    \n",
    "    # Gom nhóm Start/Stop frame\n",
    "    changes_mask = (ama != ama.shift(1)).values\n",
    "    ama_changes = ama[changes_mask]\n",
    "    meta_changes = meta[changes_mask]\n",
    "    \n",
    "    mask = ama_changes.values != 'background'\n",
    "    \n",
    "    submission_part = pd.DataFrame({\n",
    "        'video_id': meta_changes['video_id'][mask].values,\n",
    "        'agent_id': meta_changes['agent_id'][mask].values,\n",
    "        'target_id': meta_changes['target_id'][mask].values,\n",
    "        'action': ama_changes[mask].values,\n",
    "        'start_frame': ama_changes.index[mask],\n",
    "        'stop_frame': 0 \n",
    "    })\n",
    "    \n",
    "    # Fix stop_frame\n",
    "    stop_indices = np.where(changes_mask)[0][1:]\n",
    "    stop_indices = np.append(stop_indices, len(meta))\n",
    "    valid_stops = stop_indices[mask]\n",
    "    \n",
    "    if len(valid_stops) > 0:\n",
    "        submission_part['stop_frame'] = meta.iloc[valid_stops - 1].video_frame.values + 1\n",
    "    \n",
    "    # Giữ lại các hành vi >= 2 frames\n",
    "    if len(submission_part) > 0:\n",
    "        submission_part = submission_part[(submission_part.stop_frame - submission_part.start_frame) >= 2]\n",
    "    \n",
    "    if verbose: print(f'  [HMM Tuned] actions found: {len(submission_part)}')\n",
    "    return submission_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a03a36c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:20.645814Z",
     "iopub.status.busy": "2025-12-13T17:41:20.645616Z",
     "iopub.status.idle": "2025-12-13T17:41:21.848854Z",
     "shell.execute_reply": "2025-12-13T17:41:21.848169Z"
    },
    "papermill": {
     "duration": 1.20924,
     "end_time": "2025-12-13T17:41:21.850100",
     "exception": false,
     "start_time": "2025-12-13T17:41:20.640860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All actions: ['allogroom', 'approach', 'attack', 'attemptmount', 'avoid', 'biteobject', 'chase', 'chaseattack', 'climb', 'defend', 'dig', 'disengage', 'dominance', 'dominancegroom', 'dominancemount', 'ejaculate', 'escape', 'exploreobject', 'flinch', 'follow', 'freeze', 'genitalgroom', 'huddle', 'intromit', 'mount', 'rear', 'reciprocalsniff', 'rest', 'run', 'selfgroom', 'shepherd', 'sniff', 'sniffbody', 'sniffface', 'sniffgenital', 'submit', 'tussle', 'background']\n",
      "Computing transition matrix from metadata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8789/8789 [00:01<00:00, 7483.44it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition matrix shape: (38, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Lấy danh sách tất cả behaviors từ tập train\n",
    "behaviors_raw = list(train.behaviors_labeled.drop_duplicates().dropna())\n",
    "all_actions = set()\n",
    "for b_str in behaviors_raw:\n",
    "    try:\n",
    "        b_list = ast.literal_eval(b_str) if isinstance(b_str, str) else b_str\n",
    "        for item in b_list:\n",
    "            parts = item.replace(\"'\", \"\").split(',')\n",
    "            if len(parts) == 3:\n",
    "                all_actions.add(parts[2])\n",
    "    except: pass\n",
    "\n",
    "# QUAN TRỌNG: Thêm 'background' vào danh sách\n",
    "ALL_ACTIONS_LIST = sorted(list(all_actions)) + ['background']\n",
    "print(\"All actions:\", ALL_ACTIONS_LIST)\n",
    "\n",
    "# Tính Transition Matrix (Log scale)\n",
    "TRANS_MATRIX_LOG = estimate_transition_matrix_fast(train, ALL_ACTIONS_LIST)\n",
    "print(\"Transition matrix shape:\", TRANS_MATRIX_LOG.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd5f453",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:21.860933Z",
     "iopub.status.busy": "2025-12-13T17:41:21.860719Z",
     "iopub.status.idle": "2025-12-13T17:41:21.866371Z",
     "shell.execute_reply": "2025-12-13T17:41:21.865794Z"
    },
    "papermill": {
     "duration": 0.012128,
     "end_time": "2025-12-13T17:41:21.867420",
     "exception": false,
     "start_time": "2025-12-13T17:41:21.855292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_solution_df(dataset):\n",
    "    \"\"\"Create the solution dataframe for validating out-of-fold predictions.\n",
    "\n",
    "    From https://www.kaggle.com/code/ambrosm/mabe-validated-baseline-without-machine-learning/\n",
    "    \n",
    "    Parameters:\n",
    "    dataset: (a subset of) the train dataframe\n",
    "    \n",
    "    Return values:\n",
    "    solution: solution dataframe in the correct format for the score() function\n",
    "    \"\"\"\n",
    "    solution = []\n",
    "    for _, row in tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "    \n",
    "        # Load annotation file\n",
    "        lab_id = row['lab_id']\n",
    "        if lab_id.startswith('MABe22'): continue\n",
    "        video_id = row['video_id']\n",
    "        path = f\"/kaggle/input/MABe-mouse-behavior-detection/train_annotation/{lab_id}/{video_id}.parquet\"\n",
    "        try:\n",
    "            annot = pd.read_parquet(path)\n",
    "        except FileNotFoundError:\n",
    "            # MABe22 and one more training file lack annotations.\n",
    "            if verbose: print(f\"No annotations for {path}\")\n",
    "            continue\n",
    "    \n",
    "        # Add all annotations to the solution\n",
    "        annot['lab_id'] = lab_id\n",
    "        annot['video_id'] = video_id\n",
    "        annot['behaviors_labeled'] = row['behaviors_labeled']\n",
    "        annot['target_id'] = np.where(annot.target_id != annot.agent_id, annot['target_id'].apply(lambda s: f\"mouse{s}\"), 'self')\n",
    "        annot['agent_id'] = annot['agent_id'].apply(lambda s: f\"mouse{s}\")\n",
    "        solution.append(annot)\n",
    "    \n",
    "    solution = pd.concat(solution)\n",
    "    return solution\n",
    "\n",
    "if validate_or_submit == 'validate':\n",
    "    solution = create_solution_df(train_without_mabe22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12552bd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:21.877974Z",
     "iopub.status.busy": "2025-12-13T17:41:21.877769Z",
     "iopub.status.idle": "2025-12-13T17:41:21.886015Z",
     "shell.execute_reply": "2025-12-13T17:41:21.885453Z"
    },
    "papermill": {
     "duration": 0.014756,
     "end_time": "2025-12-13T17:41:21.886947",
     "exception": false,
     "start_time": "2025-12-13T17:41:21.872191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if validate_or_submit == 'stresstest':\n",
    "    n_videos_per_lab = 2\n",
    "    \n",
    "    try:\n",
    "        os.mkdir(f\"stresstest_tracking\")\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    rng = np.random.default_rng()\n",
    "    stresstest = pd.concat(\n",
    "        [train.query(\"video_id == 1459695188\")] # long video from BoisterousParrot\n",
    "        + [df.sample(min(n_videos_per_lab, len(df)), random_state=1) for (_, df) in train.groupby('lab_id')])\n",
    "    for _, row in tqdm(stresstest.iterrows(), total=len(stresstest)):\n",
    "        lab_id = row['lab_id']\n",
    "        video_id = row['video_id']\n",
    "        \n",
    "        # Load video\n",
    "        path = f\"/kaggle/input/MABe-mouse-behavior-detection/train_tracking/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path)\n",
    "    \n",
    "        if video_id == 1459695188: # long video from BoisterousParrot\n",
    "            vid = pd.concat([vid] * 3) # provoke out of memory (5 is too much)\n",
    "            vid['video_frame'] = np.arange(len(vid))\n",
    "    \n",
    "        # Drop some complete frames\n",
    "        dropped_frames = list(rng.choice(np.unique(vid.video_frame), size=100, replace=False))\n",
    "        vid = vid.query(\"~ video_frame.isin(@dropped_frames)\")\n",
    "        \n",
    "        # Drop a complete bodypart\n",
    "        if rng.uniform() < 0.2:\n",
    "            dropped_bodypart = rng.choice(np.unique(vid.bodypart), size=1, replace=False)[0]\n",
    "            vid = vid.query(\"bodypart != @dropped_bodypart\")\n",
    "        \n",
    "        # Drop a mouse\n",
    "        if rng.uniform() < 0.1:\n",
    "            vid = vid.query(\"mouse_id != 1\")\n",
    "        \n",
    "        # Drop random bodyparts from random frames\n",
    "        if rng.uniform() < 0.7:\n",
    "            mask = np.ones(len(vid), dtype=bool)\n",
    "            mask[:int(0.4 * len(mask))] = False\n",
    "            rng.shuffle(mask)\n",
    "            vid = vid[mask]\n",
    "    \n",
    "        # Set random coordinates of bodyparts to nan\n",
    "        if rng.uniform() < 0.7:\n",
    "            mask = np.ones(len(vid), dtype=bool)\n",
    "            mask[:int(0.2 * len(mask))] = False\n",
    "            rng.shuffle(mask)\n",
    "            vid.loc[:, 'x'] = np.where(mask, np.nan, vid.loc[:, 'x'])\n",
    "            rng.shuffle(mask)\n",
    "            vid.loc[:, 'y'] = np.where(mask, np.nan, vid.loc[:, 'y'])\n",
    "    \n",
    "        # Save the video\n",
    "        try:\n",
    "            os.mkdir(f\"stresstest_tracking/{lab_id}\")\n",
    "        except FileExistsError:\n",
    "            pass\n",
    "        new_path = f\"stresstest_tracking/{lab_id}/{video_id}.parquet\"\n",
    "        vid.to_parquet(new_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de5127cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:21.897591Z",
     "iopub.status.busy": "2025-12-13T17:41:21.897416Z",
     "iopub.status.idle": "2025-12-13T17:41:21.912064Z",
     "shell.execute_reply": "2025-12-13T17:41:21.911374Z"
    },
    "papermill": {
     "duration": 0.021398,
     "end_time": "2025-12-13T17:41:21.913160",
     "exception": false,
     "start_time": "2025-12-13T17:41:21.891762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_body_parts =  ['headpiece_bottombackleft', 'headpiece_bottombackright', 'headpiece_bottomfrontleft', 'headpiece_bottomfrontright', \n",
    "                    'headpiece_topbackleft', 'headpiece_topbackright', 'headpiece_topfrontleft', 'headpiece_topfrontright', \n",
    "                    'spine_1', 'spine_2',\n",
    "                    'tail_middle_1', 'tail_middle_2', 'tail_midpoint']\n",
    "\n",
    "def _fps_from_meta(meta_df, fallback_lookup, default_fps=30.0):\n",
    "    \"\"\"Extract FPS from metadata with fallback options\"\"\"\n",
    "    if 'frames_per_second' in meta_df.columns and pd.notnull(meta_df['frames_per_second']).any():\n",
    "        return float(meta_df['frames_per_second'].iloc[0])\n",
    "    if 'fps' in meta_df.columns and pd.notnull(meta_df['fps']).any():\n",
    "        return float(meta_df['fps'].iloc[0])\n",
    "    vid = meta_df['video_id'].iloc[0]\n",
    "    return float(fallback_lookup.get(vid, default_fps))\n",
    "\n",
    "def generate_mouse_data(dataset, traintest, traintest_directory=None, generate_single=True, generate_pair=True):\n",
    "    \"\"\"Generate batches of data in coordinate representation (FPS-Aware).\n",
    "\n",
    "    The batches have variable length, and every batch can have other columns\n",
    "    for the labels, depending on what behaviors\n",
    "    were labeled for the batch.\n",
    "\n",
    "    Every video can produce zero, one or two batches.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset: (subset of) train.csv or test.csv dataframe\n",
    "    traintest: either 'train' or 'test'\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    switch: either 'single' or 'pair'\n",
    "    data: dataframe containing coordinates of the body parts of a single mouse or of a pair of mice\n",
    "    meta: dataframe with columns ['video_id', 'agent_id', 'target_id', 'video_frame', 'frames_per_second']\n",
    "    label: dataframe with labels (0, 1), one column per action, only if traintest == 'train'\n",
    "    actions: list of actions to be predicted for this batch, only if traintest == 'test'\n",
    "    \"\"\"\n",
    "    assert traintest in ['train', 'test']\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n",
    "    for _, row in dataset.iterrows():\n",
    "        \n",
    "        # Load the video and pivot it so that one frame = one row\n",
    "        lab_id = row.lab_id\n",
    "        if lab_id.startswith('MABe22'): continue\n",
    "        video_id = row.video_id\n",
    "\n",
    "        if type(row.behaviors_labeled) != str:\n",
    "            # We cannot use videos without labeled behaviors\n",
    "            if verbose: print('No labeled behaviors:', lab_id, video_id, type(row.behaviors_labeled))\n",
    "            continue\n",
    "\n",
    "        # Get FPS for this video\n",
    "        fps = row.get('frames_per_second', row.get('fps_approx', 30.0))\n",
    "\n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path)\n",
    "        if len(np.unique(vid.bodypart)) > 5:\n",
    "            vid = vid.query(\"~ bodypart.isin(@drop_body_parts)\")\n",
    "        pvid = vid.pivot(columns=['mouse_id', 'bodypart'], index='video_frame', values=['x', 'y'])\n",
    "        if pvid.isna().any().any():\n",
    "            if verbose and traintest == 'test': print('video with missing values', video_id, traintest, len(vid), 'frames')\n",
    "        else:\n",
    "            if verbose and traintest == 'test': print('video with all values', video_id, traintest, len(vid), 'frames')\n",
    "        del vid\n",
    "        pvid = pvid.reorder_levels([1, 2, 0], axis=1).T.sort_index().T # mouse_id, body_part, xy\n",
    "        pvid /= row.pix_per_cm_approx # convert to cm\n",
    "\n",
    "        # Determine the behaviors of this video\n",
    "        vid_behaviors = json.loads(row.behaviors_labeled)\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
    "        \n",
    "        # Load the annotations\n",
    "        if traintest == 'train':\n",
    "            try:\n",
    "                annot = pd.read_parquet(path.replace('train_tracking', 'train_annotation'))\n",
    "            except FileNotFoundError:\n",
    "                # MABe22 and one more training file lack annotations.\n",
    "                # We simply drop these videos.\n",
    "                continue\n",
    "\n",
    "        # Create the single_mouse dataframes: single_mouse, single_mouse_label and single_mouse_meta\n",
    "        if generate_single:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target == 'self'\") # single-mouse behaviors of this video\n",
    "            for mouse_id_str in np.unique(vid_behaviors_subset.agent):\n",
    "                try:\n",
    "                    mouse_id = int(mouse_id_str[-1])\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"agent == @mouse_id_str\").action)\n",
    "                    single_mouse = pvid.loc[:, mouse_id]\n",
    "                    assert len(single_mouse) == len(pvid)\n",
    "                    single_mouse_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': mouse_id_str,\n",
    "                        'target_id': 'self',\n",
    "                        'video_frame': single_mouse.index,\n",
    "                        'frames_per_second': fps\n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        single_mouse_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=single_mouse.index)\n",
    "                        annot_subset = annot.query(\"(agent_id == @mouse_id) & (target_id == @mouse_id)\")\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            single_mouse_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
    "                        yield 'single', single_mouse, single_mouse_meta, single_mouse_label\n",
    "                    else:\n",
    "                        if verbose: print('- test single', video_id, mouse_id)\n",
    "                        yield 'single', single_mouse, single_mouse_meta, vid_agent_actions\n",
    "                except KeyError:\n",
    "                    pass # If there is no data for the selected agent mouse, we skip the mouse.\n",
    "\n",
    "        # Create the mouse_pair dataframes: mouse_pair, mouse_label and mouse_meta\n",
    "        if generate_pair:\n",
    "            vid_behaviors_subset = vid_behaviors.query(\"target != 'self'\")\n",
    "            if len(vid_behaviors_subset) > 0:\n",
    "                for agent, target in itertools.permutations(np.unique(pvid.columns.get_level_values('mouse_id')), 2): # int8\n",
    "                    agent_str = f\"mouse{agent}\"\n",
    "                    target_str = f\"mouse{target}\"\n",
    "                    vid_agent_actions = np.unique(vid_behaviors_subset.query(\"(agent == @agent_str) & (target == @target_str)\").action)\n",
    "                    mouse_pair = pd.concat([pvid[agent], pvid[target]], axis=1, keys=['A', 'B'])\n",
    "                    assert len(mouse_pair) == len(pvid)\n",
    "                    mouse_pair_meta = pd.DataFrame({\n",
    "                        'video_id': video_id,\n",
    "                        'agent_id': agent_str,\n",
    "                        'target_id': target_str,\n",
    "                        'video_frame': mouse_pair.index,\n",
    "                        'frames_per_second': fps\n",
    "                    })\n",
    "                    if traintest == 'train':\n",
    "                        mouse_pair_label = pd.DataFrame(0.0, columns=vid_agent_actions, index=mouse_pair.index)\n",
    "                        annot_subset = annot.query(\"(agent_id == @agent) & (target_id == @target)\")\n",
    "                        for i in range(len(annot_subset)):\n",
    "                            annot_row = annot_subset.iloc[i]\n",
    "                            mouse_pair_label.loc[annot_row['start_frame']:annot_row['stop_frame'], annot_row.action] = 1.0\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, mouse_pair_label\n",
    "                    else:\n",
    "                        if verbose: print('- test pair', video_id, agent, target)\n",
    "                        yield 'pair', mouse_pair, mouse_pair_meta, vid_agent_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb083c16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:21.923794Z",
     "iopub.status.busy": "2025-12-13T17:41:21.923601Z",
     "iopub.status.idle": "2025-12-13T17:41:21.930037Z",
     "shell.execute_reply": "2025-12-13T17:41:21.929519Z"
    },
    "papermill": {
     "duration": 0.013113,
     "end_time": "2025-12-13T17:41:21.931104",
     "exception": false,
     "start_time": "2025-12-13T17:41:21.917991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: ACTION-SPECIFIC THRESHOLDS (From FPS-Aware v4 Reference Notebook)\n",
    "# =============================================================================\n",
    "from collections import defaultdict\n",
    "\n",
    "# Action-specific threshold configuration (from v4)\n",
    "# Structure supports mode-aware thresholds (single vs pair behaviors)\n",
    "# \n",
    "# How to tune thresholds:\n",
    "# 1. Set \"default\" for global fallback (used if mode defaults not specified)\n",
    "# 2. Set \"single_default\" and \"pair_default\" for mode-specific defaults\n",
    "# 3. Add action-specific overrides in \"single\" or \"pair\" dictionaries\n",
    "# 4. Actions not explicitly listed will use the appropriate mode default\n",
    "#\n",
    "# Threshold range: typically 0.20-0.40, with 0.27 as a good starting point\n",
    "# Higher thresholds = fewer false positives, more false negatives\n",
    "# Lower thresholds = more false positives, fewer false negatives\n",
    "\n",
    "action_thresholds = {\n",
    "    \"default\": 0.27,           # Global fallback threshold\n",
    "    \"single_default\": 0.26,    # Default for single mouse behaviors (target_id == 'self')\n",
    "    \"pair_default\": 0.28,      # Default for pair behaviors (target_id != 'self')\n",
    "    \"single\": {\n",
    "        \"rear\": 0.30,          # Higher threshold - distinctive behavior, reduce false positives\n",
    "        \"groom\": 0.28,         # Slightly higher - common behavior, needs good confidence\n",
    "        \"sniff\": 0.25,         # Lower threshold - subtle behavior, improve recall\n",
    "        \"dig\": 0.29,           # Higher threshold - distinctive behavior\n",
    "        \"eat\": 0.27,           # Standard threshold - balanced precision/recall\n",
    "        \"drink\": 0.27,         # Standard threshold - balanced precision/recall\n",
    "        \"sleep\": 0.24,         # Lower threshold - rare but important, improve recall\n",
    "    },\n",
    "    \"pair\": {\n",
    "        \"attack\": 0.24,        # Lower threshold - rare but critical behavior, maximize recall\n",
    "        \"mount\": 0.28,         # Higher threshold - distinctive behavior, reduce false positives\n",
    "        \"sniff\": 0.26,         # Lower threshold - subtle social behavior, improve recall\n",
    "        \"groom\": 0.27,         # Standard threshold - balanced precision/recall\n",
    "        \"chase\": 0.25,         # Lower threshold - important social behavior, improve recall\n",
    "        \"follow\": 0.26,        # Lower threshold - subtle behavior, improve recall\n",
    "        \"approach\": 0.27,      # Standard threshold - balanced precision/recall\n",
    "    },\n",
    "}\n",
    "\n",
    "def _select_threshold_map(thresholds, mode: str):\n",
    "    \"\"\"Select the correct threshold map based on mode (single vs pair)\"\"\"\n",
    "    if isinstance(thresholds, dict):\n",
    "        # mode-aware?\n",
    "        if (\"single\" in thresholds) or (\"pair\" in thresholds) or \\\n",
    "           (\"single_default\" in thresholds) or (\"pair_default\" in thresholds):\n",
    "            base_default = float(thresholds.get(\"default\", 0.27))\n",
    "            mode_default = float(thresholds.get(f\"{mode}_default\", base_default))\n",
    "            mode_overrides = thresholds.get(mode, {}) or {}\n",
    "            out = defaultdict(lambda: mode_default)\n",
    "            out.update({str(k): float(v) for k, v in mode_overrides.items()})\n",
    "            return out\n",
    "        # plain per-action dict\n",
    "        out = defaultdict(lambda: float(thresholds.get(\"default\", 0.27)))\n",
    "        out.update({str(k): float(v) for k, v in thresholds.items() if k != \"default\"})\n",
    "        return out\n",
    "    return defaultdict(lambda: 0.27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1025690c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:21.941605Z",
     "iopub.status.busy": "2025-12-13T17:41:21.941409Z",
     "iopub.status.idle": "2025-12-13T17:41:21.951416Z",
     "shell.execute_reply": "2025-12-13T17:41:21.950877Z"
    },
    "papermill": {
     "duration": 0.016567,
     "end_time": "2025-12-13T17:41:21.952474",
     "exception": false,
     "start_time": "2025-12-13T17:41:21.935907",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: PREDICT MULTICLASS (FPS-Aware Adaptive Thresholding from v4)\n",
    "# =============================================================================\n",
    "def predict_multiclass_adaptive(pred, meta, action_thresholds):\n",
    "    \"\"\"Adaptive thresholding per action + FPS-aware temporal smoothing\"\"\"\n",
    "    # Extract FPS for FPS-aware smoothing and filtering\n",
    "    fps = _fps_from_meta(meta, {}, default_fps=30.0)\n",
    "    \n",
    "    # Apply FPS-aware temporal smoothing (scaled to configurable base window)\n",
    "    smoothing_window = max(3, int(round(SMOOTHING_WINDOW_FRAMES_AT_30FPS * fps / 30.0)))\n",
    "    pred_smoothed = pred.rolling(window=smoothing_window, min_periods=1, center=True).mean()\n",
    "\n",
    "    # Robust mode detection: check if all target_ids are 'self' for single mode\n",
    "    mode = 'pair'  # default to pair\n",
    "    try:\n",
    "        if 'target_id' in meta.columns:\n",
    "            unique_targets = meta['target_id'].unique()\n",
    "            if len(unique_targets) == 1 and unique_targets[0] == 'self':\n",
    "                mode = 'single'\n",
    "    except (KeyError, AttributeError, Exception):\n",
    "        # If detection fails, default to pair mode\n",
    "        pass\n",
    "\n",
    "    ama = np.argmax(pred_smoothed, axis=1)\n",
    "    th_map = _select_threshold_map(action_thresholds, mode)\n",
    "\n",
    "    max_probs = pred_smoothed.max(axis=1)\n",
    "    threshold_mask = np.zeros(len(pred_smoothed), dtype=bool)\n",
    "    for i, action in enumerate(pred_smoothed.columns):\n",
    "        action_mask = (ama == i)\n",
    "        threshold = th_map[action]\n",
    "        threshold_mask |= (action_mask & (max_probs >= threshold))\n",
    "\n",
    "    ama = np.where(threshold_mask, ama, -1)\n",
    "    ama = pd.Series(ama, index=meta.video_frame)\n",
    "    \n",
    "    changes_mask = (ama != ama.shift(1)).values\n",
    "    ama_changes = ama[changes_mask]\n",
    "    meta_changes = meta[changes_mask]\n",
    "    mask = ama_changes.values >= 0\n",
    "    mask[-1] = False\n",
    "    \n",
    "    submission_part = pd.DataFrame({\n",
    "        'video_id': meta_changes['video_id'][mask].values,\n",
    "        'agent_id': meta_changes['agent_id'][mask].values,\n",
    "        'target_id': meta_changes['target_id'][mask].values,\n",
    "        'action': pred.columns[ama_changes[mask].values],\n",
    "        'start_frame': ama_changes.index[mask],\n",
    "        'stop_frame': ama_changes.index[1:][mask[:-1]]\n",
    "    })\n",
    "    \n",
    "    # Handle stop frames: if next change is in different video/agent/target, set stop to end of current video\n",
    "    stop_meta = meta_changes.iloc[1:][mask[:-1]] if len(mask) > 1 else pd.DataFrame()\n",
    "    \n",
    "    for i in range(len(submission_part)):\n",
    "        video_id = submission_part.video_id.iloc[i]\n",
    "        agent_id = submission_part.agent_id.iloc[i]\n",
    "        target_id = submission_part.target_id.iloc[i]\n",
    "        \n",
    "        # Check if we need to adjust stop frame\n",
    "        if i < len(stop_meta):\n",
    "            next_row = stop_meta.iloc[i]\n",
    "            if (next_row['video_id'] != video_id or \n",
    "                next_row['agent_id'] != agent_id or \n",
    "                next_row['target_id'] != target_id):\n",
    "                # Next event is different video/agent/target, set stop to end of current video\n",
    "                new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n",
    "                submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
    "        else:\n",
    "            # Last event, set stop to end of video\n",
    "            new_stop_frame = meta.query(\"(video_id == @video_id)\").video_frame.max() + 1\n",
    "            submission_part.iat[i, submission_part.columns.get_loc('stop_frame')] = new_stop_frame\n",
    "    \n",
    "    # Filter out very short events (likely noise) - FPS-aware minimum duration\n",
    "    min_duration_frames = max(2, int(round(MIN_DURATION_SECONDS * fps)))\n",
    "    duration = submission_part.stop_frame - submission_part.start_frame\n",
    "    submission_part = submission_part[duration >= min_duration_frames].reset_index(drop=True)\n",
    "    \n",
    "    if len(submission_part) > 0:\n",
    "        assert (submission_part.stop_frame > submission_part.start_frame).all(), 'stop <= start'\n",
    "    \n",
    "    if verbose: print(f'  actions found: {len(submission_part)}')\n",
    "    return submission_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbf8eeb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:21.963437Z",
     "iopub.status.busy": "2025-12-13T17:41:21.963242Z",
     "iopub.status.idle": "2025-12-13T17:41:22.003918Z",
     "shell.execute_reply": "2025-12-13T17:41:22.003363Z"
    },
    "papermill": {
     "duration": 0.047403,
     "end_time": "2025-12-13T17:41:22.004899",
     "exception": false,
     "start_time": "2025-12-13T17:41:21.957496",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: ADVANCED FEATURE ENGINEERING (Updated with Interaction V2)\n",
    "# =============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "def _scale(n_frames_at_30fps, fps, ref=30.0):\n",
    "    return max(1, int(round(n_frames_at_30fps * float(fps) / ref)))\n",
    "\n",
    "def _scale_signed(n_frames_at_30fps, fps, ref=30.0):\n",
    "    if n_frames_at_30fps == 0: return 0\n",
    "    s = 1 if n_frames_at_30fps > 0 else -1\n",
    "    mag = max(1, int(round(abs(n_frames_at_30fps) * float(fps) / ref)))\n",
    "    return s * mag\n",
    "\n",
    "# --- Feature Helpers ---\n",
    "def add_curvature_features(X, center_x, center_y, fps):\n",
    "    vel_x = center_x.diff()\n",
    "    vel_y = center_y.diff()\n",
    "    acc_x = vel_x.diff()\n",
    "    acc_y = vel_y.diff()\n",
    "    cross_prod = vel_x * acc_y - vel_y * acc_x\n",
    "    vel_mag = np.sqrt(vel_x**2 + vel_y**2)\n",
    "    curvature = np.abs(cross_prod) / (vel_mag**3 + 1e-6)\n",
    "    for w in [30, 60]:\n",
    "        ws = _scale(w, fps)\n",
    "        X[f'curv_mean_{w}'] = curvature.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
    "    angle = np.arctan2(vel_y, vel_x)\n",
    "    angle_change = np.abs(angle.diff())\n",
    "    w = 30\n",
    "    ws = _scale(w, fps)\n",
    "    X[f'turn_rate_{w}'] = angle_change.rolling(ws, min_periods=max(1, ws // 6)).sum()\n",
    "    return X\n",
    "\n",
    "def add_multiscale_features(X, center_x, center_y, fps):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
    "    scales = [10, 40, 160]\n",
    "    for scale in scales:\n",
    "        ws = _scale(scale, fps)\n",
    "        if len(speed) >= ws:\n",
    "            X[f'sp_m{scale}'] = speed.rolling(ws, min_periods=max(1, ws // 4)).mean()\n",
    "            X[f'sp_s{scale}'] = speed.rolling(ws, min_periods=max(1, ws // 4)).std()\n",
    "    if len(scales) >= 2 and f'sp_m{scales[0]}' in X.columns and f'sp_m{scales[-1]}' in X.columns:\n",
    "        X['sp_ratio'] = X[f'sp_m{scales[0]}'] / (X[f'sp_m{scales[-1]}'] + 1e-6)\n",
    "    return X\n",
    "\n",
    "def add_state_features(X, center_x, center_y, fps):\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
    "    w_ma = _scale(15, fps)\n",
    "    speed_ma = speed.rolling(w_ma, min_periods=max(1, w_ma // 3)).mean()\n",
    "    try:\n",
    "        bins = [-np.inf, 0.5 * fps, 2.0 * fps, 5.0 * fps, np.inf]\n",
    "        speed_states = pd.cut(speed_ma, bins=bins, labels=[0, 1, 2, 3]).astype(float)\n",
    "        for window in [60, 120]:\n",
    "            ws = _scale(window, fps)\n",
    "            if len(speed_states) >= ws:\n",
    "                for state in [0, 1, 2, 3]:\n",
    "                    X[f's{state}_{window}'] = ((speed_states == state).astype(float)\n",
    "                        .rolling(ws, min_periods=max(1, ws // 6)).mean())\n",
    "                state_changes = (speed_states != speed_states.shift(1)).astype(float)\n",
    "                X[f'trans_{window}'] = state_changes.rolling(ws, min_periods=max(1, ws // 6)).sum()\n",
    "    except: pass\n",
    "    return X\n",
    "\n",
    "def add_longrange_features(X, center_x, center_y, fps):\n",
    "    for window in [120, 240]:\n",
    "        ws = _scale(window, fps)\n",
    "        if len(center_x) >= ws:\n",
    "            X[f'x_ml{window}'] = center_x.rolling(ws, min_periods=max(5, ws // 6)).mean()\n",
    "            X[f'y_ml{window}'] = center_y.rolling(ws, min_periods=max(5, ws // 6)).mean()\n",
    "    for span in [60, 120]:\n",
    "        s = _scale(span, fps)\n",
    "        X[f'x_e{span}'] = center_x.ewm(span=s, min_periods=1).mean()\n",
    "        X[f'y_e{span}'] = center_y.ewm(span=s, min_periods=1).mean()\n",
    "    speed = np.sqrt(center_x.diff()**2 + center_y.diff()**2) * float(fps)\n",
    "    for window in [60, 120]:\n",
    "        ws = _scale(window, fps)\n",
    "        if len(speed) >= ws:\n",
    "            X[f'sp_pct{window}'] = speed.rolling(ws, min_periods=max(5, ws // 6)).rank(pct=True)\n",
    "    return X\n",
    "\n",
    "def add_interaction_features_v2(X, mouse_pair, avail_A, avail_B, fps):\n",
    "    \"\"\"NEW: Leader-Follower & Chase Dynamics features from Reference Notebook\"\"\"\n",
    "    if 'body_center' not in avail_A or 'body_center' not in avail_B:\n",
    "        return X\n",
    "    \n",
    "    rel_x = mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x']\n",
    "    rel_y = mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y']\n",
    "    rel_dist = np.sqrt(rel_x**2 + rel_y**2)\n",
    "    \n",
    "    A_vx = mouse_pair['A']['body_center']['x'].diff()\n",
    "    A_vy = mouse_pair['A']['body_center']['y'].diff()\n",
    "    B_vx = mouse_pair['B']['body_center']['x'].diff()\n",
    "    B_vy = mouse_pair['B']['body_center']['y'].diff()\n",
    "    \n",
    "    # Leader score: Positive if moving TOWARDS other mouse\n",
    "    A_lead = (A_vx * rel_x + A_vy * rel_y) / (np.sqrt(A_vx**2 + A_vy**2) * rel_dist + 1e-6)\n",
    "    B_lead = (B_vx * (-rel_x) + B_vy * (-rel_y)) / (np.sqrt(B_vx**2 + B_vy**2) * rel_dist + 1e-6)\n",
    "    \n",
    "    for window in [30, 60]:\n",
    "        ws = _scale(window, fps)\n",
    "        X[f'A_ld{window}'] = A_lead.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
    "        X[f'B_ld{window}'] = B_lead.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
    "        \n",
    "    # Chase metric\n",
    "    approach = -rel_dist.diff()\n",
    "    chase = approach * B_lead\n",
    "    w = 30\n",
    "    ws = _scale(w, fps)\n",
    "    X[f'chase_{w}'] = chase.rolling(ws, min_periods=max(1, ws // 6)).mean()\n",
    "    \n",
    "    # Velocity Correlation\n",
    "    for window in [60, 120]:\n",
    "        ws = _scale(window, fps)\n",
    "        A_sp = np.sqrt(A_vx**2 + A_vy**2)\n",
    "        B_sp = np.sqrt(B_vx**2 + B_vy**2)\n",
    "        X[f'sp_cor{window}'] = A_sp.rolling(ws, min_periods=max(1, ws // 6)).corr(B_sp)\n",
    "        \n",
    "    return X\n",
    "\n",
    "# --- Main Transforms ---\n",
    "\n",
    "def transform_single(single_mouse, body_parts_tracked, fps=30.0):\n",
    "    available_body_parts = single_mouse.columns.get_level_values(0)\n",
    "    X = pd.DataFrame({\n",
    "        f\"{p1}+{p2}\": np.square(single_mouse[p1] - single_mouse[p2]).sum(axis=1, skipna=False)\n",
    "        for p1, p2 in itertools.combinations(body_parts_tracked, 2)\n",
    "        if p1 in available_body_parts and p2 in available_body_parts\n",
    "    })\n",
    "    X = X.reindex(columns=[f\"{p1}+{p2}\" for p1, p2 in itertools.combinations(body_parts_tracked, 2)], copy=False)\n",
    "\n",
    "    if all(p in single_mouse.columns for p in ['ear_left', 'ear_right', 'tail_base']):\n",
    "        lag = _scale(10, fps)\n",
    "        shifted = single_mouse[['ear_left', 'ear_right', 'tail_base']].shift(lag)\n",
    "        speeds = pd.DataFrame({\n",
    "            'sp_lf': np.square(single_mouse['ear_left'] - shifted['ear_left']).sum(axis=1, skipna=False),\n",
    "            'sp_rt': np.square(single_mouse['ear_right'] - shifted['ear_right']).sum(axis=1, skipna=False),\n",
    "            'sp_lf2': np.square(single_mouse['ear_left'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "            'sp_rt2': np.square(single_mouse['ear_right'] - shifted['tail_base']).sum(axis=1, skipna=False),\n",
    "        })\n",
    "        X = pd.concat([X, speeds], axis=1)\n",
    "\n",
    "    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n",
    "        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n",
    "\n",
    "    if all(p in available_body_parts for p in ['nose', 'body_center', 'tail_base']):\n",
    "        v1 = single_mouse['nose'] - single_mouse['body_center']\n",
    "        v2 = single_mouse['tail_base'] - single_mouse['body_center']\n",
    "        X['body_ang'] = (v1['x'] * v2['x'] + v1['y'] * v2['y']) / (\n",
    "            np.sqrt(v1['x']**2 + v1['y']**2) * np.sqrt(v2['x']**2 + v2['y']**2) + 1e-6)\n",
    "\n",
    "    if 'body_center' in available_body_parts:\n",
    "        cx = single_mouse['body_center']['x']\n",
    "        cy = single_mouse['body_center']['y']\n",
    "        for w in [5, 15, 30, 60]:\n",
    "            ws = _scale(w, fps)\n",
    "            roll = dict(min_periods=1, center=True)\n",
    "            X[f'cx_m{w}'] = cx.rolling(ws, **roll).mean()\n",
    "            X[f'cy_m{w}'] = cy.rolling(ws, **roll).mean()\n",
    "            X[f'cx_s{w}'] = cx.rolling(ws, **roll).std()\n",
    "            X[f'cy_s{w}'] = cy.rolling(ws, **roll).std()\n",
    "            X[f'x_rng{w}'] = cx.rolling(ws, **roll).max() - cx.rolling(ws, **roll).min()\n",
    "            X[f'y_rng{w}'] = cy.rolling(ws, **roll).max() - cy.rolling(ws, **roll).min()\n",
    "            X[f'disp{w}'] = np.sqrt(cx.diff().rolling(ws, min_periods=1).sum()**2 +\n",
    "                                     cy.diff().rolling(ws, min_periods=1).sum()**2)\n",
    "            X[f'act{w}'] = np.sqrt(cx.diff().rolling(ws, min_periods=1).var() +\n",
    "                                   cy.diff().rolling(ws, min_periods=1).var())\n",
    "\n",
    "        X = add_curvature_features(X, cx, cy, fps)\n",
    "        X = add_multiscale_features(X, cx, cy, fps)\n",
    "        X = add_state_features(X, cx, cy, fps)\n",
    "        X = add_longrange_features(X, cx, cy, fps)\n",
    "\n",
    "    if all(p in available_body_parts for p in ['nose', 'tail_base']):\n",
    "        nt_dist = np.sqrt((single_mouse['nose']['x'] - single_mouse['tail_base']['x'])**2 +\n",
    "                          (single_mouse['nose']['y'] - single_mouse['tail_base']['y'])**2)\n",
    "        for lag in [10, 20, 40]:\n",
    "            l = _scale(lag, fps)\n",
    "            X[f'nt_lg{lag}'] = nt_dist.shift(l)\n",
    "            X[f'nt_df{lag}'] = nt_dist - nt_dist.shift(l)\n",
    "\n",
    "    if all(p in available_body_parts for p in ['ear_left', 'ear_right']):\n",
    "        ear_d = np.sqrt((single_mouse['ear_left']['x'] - single_mouse['ear_right']['x'])**2 +\n",
    "                        (single_mouse['ear_left']['y'] - single_mouse['ear_right']['y'])**2)\n",
    "        for off in [-30, -20, -10, 10, 20, 30]:\n",
    "            o = _scale_signed(off, fps)\n",
    "            X[f'ear_o{off}'] = ear_d.shift(-o)\n",
    "        w = _scale(30, fps)\n",
    "        X['ear_con'] = ear_d.rolling(w, min_periods=1, center=True).std() / \\\n",
    "                       (ear_d.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n",
    "\n",
    "    return X.astype(np.float32, copy=False)\n",
    "\n",
    "def transform_pair(mouse_pair, body_parts_tracked, fps=30.0):\n",
    "    avail_A = mouse_pair['A'].columns.get_level_values(0)\n",
    "    avail_B = mouse_pair['B'].columns.get_level_values(0)\n",
    "\n",
    "    X = pd.DataFrame({\n",
    "        f\"12+{p1}+{p2}\": np.square(mouse_pair['A'][p1] - mouse_pair['B'][p2]).sum(axis=1, skipna=False)\n",
    "        for p1, p2 in itertools.product(body_parts_tracked, repeat=2)\n",
    "        if p1 in avail_A and p2 in avail_B\n",
    "    })\n",
    "    X = X.reindex(columns=[f\"12+{p1}+{p2}\" for p1, p2 in itertools.product(body_parts_tracked, repeat=2)], copy=False)\n",
    "\n",
    "    if ('A', 'ear_left') in mouse_pair.columns and ('B', 'ear_left') in mouse_pair.columns:\n",
    "        lag = _scale(10, fps)\n",
    "        shA = mouse_pair['A']['ear_left'].shift(lag)\n",
    "        shB = mouse_pair['B']['ear_left'].shift(lag)\n",
    "        speeds = pd.DataFrame({\n",
    "            'sp_A': np.square(mouse_pair['A']['ear_left'] - shA).sum(axis=1, skipna=False),\n",
    "            'sp_AB': np.square(mouse_pair['A']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "            'sp_B': np.square(mouse_pair['B']['ear_left'] - shB).sum(axis=1, skipna=False),\n",
    "        })\n",
    "        X = pd.concat([X, speeds], axis=1)\n",
    "\n",
    "    if 'nose+tail_base' in X.columns and 'ear_left+ear_right' in X.columns:\n",
    "        X['elong'] = X['nose+tail_base'] / (X['ear_left+ear_right'] + 1e-6)\n",
    "\n",
    "    if all(p in avail_A for p in ['nose', 'tail_base']) and all(p in avail_B for p in ['nose', 'tail_base']):\n",
    "        dir_A = mouse_pair['A']['nose'] - mouse_pair['A']['tail_base']\n",
    "        dir_B = mouse_pair['B']['nose'] - mouse_pair['B']['tail_base']\n",
    "        X['rel_ori'] = (dir_A['x'] * dir_B['x'] + dir_A['y'] * dir_B['y']) / (\n",
    "            np.sqrt(dir_A['x']**2 + dir_A['y']**2) * np.sqrt(dir_B['x']**2 + dir_B['y']**2) + 1e-6)\n",
    "\n",
    "    if all(p in avail_A for p in ['nose']) and all(p in avail_B for p in ['nose']):\n",
    "        cur = np.square(mouse_pair['A']['nose'] - mouse_pair['B']['nose']).sum(axis=1, skipna=False)\n",
    "        lag = _scale(10, fps)\n",
    "        shA_n = mouse_pair['A']['nose'].shift(lag)\n",
    "        shB_n = mouse_pair['B']['nose'].shift(lag)\n",
    "        past = np.square(shA_n - shB_n).sum(axis=1, skipna=False)\n",
    "        X['appr'] = cur - past\n",
    "\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        cd = np.sqrt((mouse_pair['A']['body_center']['x'] - mouse_pair['B']['body_center']['x'])**2 +\n",
    "                     (mouse_pair['A']['body_center']['y'] - mouse_pair['B']['body_center']['y'])**2)\n",
    "        X['v_cls'] = (cd < 5.0).astype(float)\n",
    "        X['cls']   = ((cd >= 5.0) & (cd < 15.0)).astype(float)\n",
    "        X['med']   = ((cd >= 15.0) & (cd < 30.0)).astype(float)\n",
    "        X['far']   = (cd >= 30.0).astype(float)\n",
    "        \n",
    "        # --- ORIGINAL INTERACTION FEATURES ---\n",
    "        cd_full = np.square(mouse_pair['A']['body_center'] - mouse_pair['B']['body_center']).sum(axis=1, skipna=False)\n",
    "        for w in [5, 15, 30, 60]:\n",
    "            ws = _scale(w, fps)\n",
    "            roll = dict(min_periods=1, center=True)\n",
    "            X[f'd_m{w}']  = cd_full.rolling(ws, **roll).mean()\n",
    "            X[f'd_s{w}']  = cd_full.rolling(ws, **roll).std()\n",
    "            X[f'd_mn{w}'] = cd_full.rolling(ws, **roll).min()\n",
    "            X[f'd_mx{w}'] = cd_full.rolling(ws, **roll).max()\n",
    "\n",
    "            d_var = cd_full.rolling(ws, **roll).var()\n",
    "            X[f'int{w}'] = 1 / (1 + d_var)\n",
    "\n",
    "            Axd = mouse_pair['A']['body_center']['x'].diff()\n",
    "            Ayd = mouse_pair['A']['body_center']['y'].diff()\n",
    "            Bxd = mouse_pair['B']['body_center']['x'].diff()\n",
    "            Byd = mouse_pair['B']['body_center']['y'].diff()\n",
    "            coord = Axd * Bxd + Ayd * Byd\n",
    "            X[f'co_m{w}'] = coord.rolling(ws, **roll).mean()\n",
    "            X[f'co_s{w}'] = coord.rolling(ws, **roll).std()\n",
    "\n",
    "        # --- USE THE NEW INTERACTION V2 FUNCTION HERE ---\n",
    "        X = add_interaction_features_v2(X, mouse_pair, avail_A, avail_B, fps)\n",
    "\n",
    "    if 'nose' in avail_A and 'nose' in avail_B:\n",
    "        nn = np.sqrt((mouse_pair['A']['nose']['x'] - mouse_pair['B']['nose']['x'])**2 +\n",
    "                     (mouse_pair['A']['nose']['y'] - mouse_pair['B']['nose']['y'])**2)\n",
    "        for lag in [10, 20, 40]:\n",
    "            l = _scale(lag, fps)\n",
    "            X[f'nn_lg{lag}']  = nn.shift(l)\n",
    "            X[f'nn_ch{lag}']  = nn - nn.shift(l)\n",
    "            is_cl = (nn < 10.0).astype(float)\n",
    "            X[f'cl_ps{lag}']  = is_cl.rolling(l, min_periods=1).mean()\n",
    "\n",
    "    if 'body_center' in avail_A and 'body_center' in avail_B:\n",
    "        Avx = mouse_pair['A']['body_center']['x'].diff()\n",
    "        Avy = mouse_pair['A']['body_center']['y'].diff()\n",
    "        Bvx = mouse_pair['B']['body_center']['x'].diff()\n",
    "        Bvy = mouse_pair['B']['body_center']['y'].diff()\n",
    "        val = (Avx * Bvx + Avy * Bvy) / (np.sqrt(Avx**2 + Avy**2) * np.sqrt(Bvx**2 + Bvy**2) + 1e-6)\n",
    "\n",
    "        for off in [-20, -10, 0, 10, 20]:\n",
    "            o = _scale_signed(off, fps)\n",
    "            X[f'va_{off}'] = val.shift(-o)\n",
    "\n",
    "        w = _scale(30, fps)\n",
    "        X['int_con'] = cd_full.rolling(w, min_periods=1, center=True).std() / \\\n",
    "                       (cd_full.rolling(w, min_periods=1, center=True).mean() + 1e-6)\n",
    "\n",
    "    return X.astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99387a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:22.015513Z",
     "iopub.status.busy": "2025-12-13T17:41:22.015301Z",
     "iopub.status.idle": "2025-12-13T17:41:22.022704Z",
     "shell.execute_reply": "2025-12-13T17:41:22.022167Z"
    },
    "papermill": {
     "duration": 0.013862,
     "end_time": "2025-12-13T17:41:22.023659",
     "exception": false,
     "start_time": "2025-12-13T17:41:22.009797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: Enhanced cross_validate_classifier (Replace in cross_validate_classifier)\n",
    "# =============================================================================\n",
    "\n",
    "# ADD this at the beginning of cross_validate_classifier function,\n",
    "# right after the function definition line:\n",
    "\n",
    "def cross_validate_classifier(binary_classifier, X, label, meta):\n",
    "    \"\"\"Cross-validate a binary classifier per action and a multi-class classifier over all actions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    binary_classifier: classifier with predict_proba (can be a list of classifiers for ensemble)\n",
    "    X: 2d array-like (distance representation) of shape (n_samples, n_features)\n",
    "    label: dataframe with binary targets (one column per action, may have missing values), index doesn't matter\n",
    "    meta: dataframe with columns ['video_id', 'agent_id', 'target_id', 'video_frame'], index doesn't matter\n",
    "\n",
    "    Output\n",
    "    ------\n",
    "    appends to f1_list (binary) and submission_list (multi-class)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Cross-validate a binary classifier for every action\n",
    "    oof = pd.DataFrame(index=meta.video_frame) # will get a column per action\n",
    "    for action in label.columns:\n",
    "        # Filter for samples (video frames) with a defined target (i.e., target is not nan)\n",
    "        action_mask = ~ label[action].isna().values\n",
    "        X_action = X[action_mask]\n",
    "        y_action = label[action][action_mask].values.astype(int)\n",
    "        p = y_action.mean()\n",
    "        baseline_score = p / (1 + p)\n",
    "        groups_action = meta.video_id[action_mask] # ensure validation has unseen videos\n",
    "        if len(np.unique(groups_action)) < 5:\n",
    "            continue # GroupKFold would fail with fewer than n_splits groups\n",
    "\n",
    "        if not (y_action == 0).all():\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "                # Use first model from ensemble for cross-validation\n",
    "                if isinstance(binary_classifier, list):\n",
    "                    oof_action = cross_val_predict(binary_classifier[0], X_action, y_action, \n",
    "                                                   groups=groups_action, cv=GroupKFold(), method='predict_proba')\n",
    "                else:\n",
    "                    oof_action = cross_val_predict(binary_classifier, X_action, y_action, \n",
    "                                                   groups=groups_action, cv=GroupKFold(), method='predict_proba')\n",
    "            oof_action = oof_action[:, 1]\n",
    "        else:\n",
    "            oof_action = np.zeros(len(y_action))\n",
    "        \n",
    "        # Use adaptive threshold for this action\n",
    "        mode = 'single' if 'target_id' in meta.columns and meta['target_id'].eq('self').all() else 'pair'\n",
    "        th_map = _select_threshold_map(action_thresholds, mode)\n",
    "        action_threshold = th_map[action]\n",
    "        \n",
    "        f1 = f1_score(y_action, (oof_action >= action_threshold), zero_division=0)\n",
    "        ch = '>' if f1 > baseline_score else '=' if f1 == baseline_score else '<'\n",
    "        print(f\"  F1: {f1:.3f} {ch} ({baseline_score:.3f}) {action} (th={action_threshold:.3f})\")\n",
    "        f1_list.append((body_parts_tracked_str, action, f1))\n",
    "        oof_column = np.zeros(len(label))\n",
    "        oof_column[action_mask] = oof_action\n",
    "        oof[action] = oof_column\n",
    "\n",
    "    # Make the multi-class prediction with adaptive thresholding\n",
    "    submission_part = predict_multiclass_adaptive(oof, meta, action_thresholds)\n",
    "    submission_list.append(submission_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d7ea17c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:22.034820Z",
     "iopub.status.busy": "2025-12-13T17:41:22.034627Z",
     "iopub.status.idle": "2025-12-13T17:41:22.047602Z",
     "shell.execute_reply": "2025-12-13T17:41:22.047080Z"
    },
    "papermill": {
     "duration": 0.020135,
     "end_time": "2025-12-13T17:41:22.048737",
     "exception": false,
     "start_time": "2025-12-13T17:41:22.028602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL: SUBMIT ENSEMBLE (FPS-Aware Version from v4)\n",
    "# =============================================================================\n",
    "def submit_ensemble(body_parts_tracked_str, switch_tr, X_tr, label, n_samples):\n",
    "    # Train ensemble of models for every action\n",
    "    X_tr_np = X_tr.to_numpy(np.float32, copy=False) if hasattr(X_tr, 'to_numpy') else np.asarray(X_tr, dtype=np.float32)\n",
    "    del X_tr; gc.collect()\n",
    "    \n",
    "    # --- MODEL DEFINITIONS ---\n",
    "    models = []\n",
    "    \n",
    "    # Model 1: LGBM 225 (Baseline from v4)\n",
    "    models.append(make_pipeline(\n",
    "        StratifiedSubsetClassifier(\n",
    "            lightgbm.LGBMClassifier(\n",
    "                n_estimators=225, learning_rate=0.07, min_child_samples=40,\n",
    "                num_leaves=31, subsample=0.8, colsample_bytree=0.8, verbose=-1,\n",
    "                random_state=SEED, bagging_seed=SEED, feature_fraction_seed=SEED, data_random_seed=SEED\n",
    "            ), int(n_samples/1.3),\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    # Model 2: LGBM 150 (Deep)\n",
    "    models.append(make_pipeline(\n",
    "        StratifiedSubsetClassifier(\n",
    "            lightgbm.LGBMClassifier(\n",
    "                n_estimators=150, learning_rate=0.1, min_child_samples=20,\n",
    "                num_leaves=63, max_depth=8, subsample=0.7, colsample_bytree=0.9,\n",
    "                reg_alpha=0.1, reg_lambda=0.1, verbose=-1,\n",
    "                random_state=SEED, bagging_seed=SEED, feature_fraction_seed=SEED, data_random_seed=SEED\n",
    "            ), int(n_samples/2),\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    # Model 3: LGBM 100 (Very Deep)\n",
    "    models.append(make_pipeline(\n",
    "        StratifiedSubsetClassifier(\n",
    "            lightgbm.LGBMClassifier(\n",
    "                n_estimators=100, learning_rate=0.05, min_child_samples=30,\n",
    "                num_leaves=127, max_depth=10, subsample=0.75, verbose=-1,\n",
    "                random_state=SEED, bagging_seed=SEED, feature_fraction_seed=SEED, data_random_seed=SEED\n",
    "            ), int(n_samples/3),\n",
    "        )\n",
    "    ))\n",
    "    \n",
    "    if 'XGBOOST_AVAILABLE' in globals() and XGBOOST_AVAILABLE:\n",
    "        models.append(make_pipeline(\n",
    "            StratifiedSubsetClassifier(\n",
    "                XGBClassifier(\n",
    "                    n_estimators=180, learning_rate=0.08, max_depth=6,\n",
    "                    min_child_weight=5, subsample=0.8, colsample_bytree=0.8,\n",
    "                    tree_method='hist', verbosity=0,\n",
    "                    random_state=SEED\n",
    "                ), int(n_samples/1.5),\n",
    "            )\n",
    "        ))\n",
    "    \n",
    "    if 'CATBOOST_AVAILABLE' in globals() and CATBOOST_AVAILABLE:\n",
    "        models.append(make_pipeline(\n",
    "            StratifiedSubsetClassifier(\n",
    "                CatBoostClassifier(\n",
    "                    iterations=120, learning_rate=0.1, depth=6,\n",
    "                    verbose=False, allow_writing_files=False,\n",
    "                    random_seed=SEED\n",
    "                ), n_samples,\n",
    "            )\n",
    "        ))\n",
    "\n",
    "    # --- TRAINING LOOP ---\n",
    "    model_list = []\n",
    "    for action in label.columns:\n",
    "        y_raw = label[action].to_numpy()\n",
    "        mask = ~pd.isna(y_raw)\n",
    "        y_action = y_raw[mask].astype(int)\n",
    "        if not (y_action == 0).all() and np.sum(y_action) >= 5:\n",
    "            trained = []\n",
    "            idx = np.flatnonzero(mask)\n",
    "            for m in models:\n",
    "                m_clone = clone(m)\n",
    "                m_clone.fit(X_tr_np[idx], y_action)\n",
    "                trained.append(m_clone)\n",
    "            model_list.append((action, trained))\n",
    "\n",
    "    del X_tr_np; gc.collect()\n",
    "\n",
    "    # --- PREDICTION LOOP ---\n",
    "    body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "    if len(body_parts_tracked) > 5:\n",
    "        body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "\n",
    "    test_subset = test[test.body_parts_tracked == body_parts_tracked_str]\n",
    "    generator = generate_mouse_data(\n",
    "        test_subset, 'test',\n",
    "        generate_single=(switch_tr == 'single'),\n",
    "        generate_pair=(switch_tr == 'pair')\n",
    "    )\n",
    "\n",
    "    fps_lookup = (\n",
    "        test_subset[['video_id', 'frames_per_second']]\n",
    "        .drop_duplicates('video_id')\n",
    "        .set_index('video_id')['frames_per_second']\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"n_videos: {len(test_subset)}, n_models: {len(models)}\")\n",
    "\n",
    "    for switch_te, data_te, meta_te, actions_te in generator:\n",
    "        assert switch_te == switch_tr\n",
    "        try:\n",
    "            fps_i = _fps_from_meta(meta_te, fps_lookup, default_fps=30.0)\n",
    "\n",
    "            if switch_te == 'single':\n",
    "                X_te = transform_single(data_te, body_parts_tracked, fps_i).astype(np.float32)\n",
    "            else:\n",
    "                X_te = transform_pair(data_te, body_parts_tracked, fps_i).astype(np.float32)\n",
    "\n",
    "            X_te_np = X_te.to_numpy(np.float32, copy=False)\n",
    "            del X_te, data_te; gc.collect()\n",
    "\n",
    "            pred = pd.DataFrame(index=meta_te.video_frame)\n",
    "            for action, trained in model_list:\n",
    "                if action in actions_te:\n",
    "                    probs = [m.predict_proba(X_te_np)[:, 1] for m in trained]\n",
    "                    pred[action] = np.mean(probs, axis=0)\n",
    "\n",
    "            del X_te_np; gc.collect()\n",
    "\n",
    "            if pred.shape[1] != 0:\n",
    "                sub_part = predict_multiclass_adaptive(pred, meta_te, action_thresholds)\n",
    "                submission_list.append(sub_part)\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(\"  ERROR: no training data\")\n",
    "\n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                error_msg = str(e)\n",
    "                if len(error_msg) > 200:\n",
    "                    error_msg = error_msg[:200] + \"...\"\n",
    "                print(f\"  ERROR: {error_msg}\")\n",
    "                if verbose:\n",
    "                    print(f\"  Traceback: {traceback.format_exc()[:300]}\")\n",
    "            try:\n",
    "                del data_te\n",
    "            except Exception:\n",
    "                pass\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbfea650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T17:41:22.059403Z",
     "iopub.status.busy": "2025-12-13T17:41:22.059226Z",
     "iopub.status.idle": "2025-12-13T19:28:12.970436Z",
     "shell.execute_reply": "2025-12-13T19:28:12.969543Z"
    },
    "papermill": {
     "duration": 6410.924963,
     "end_time": "2025-12-13T19:28:12.978593",
     "exception": false,
     "start_time": "2025-12-13T17:41:22.053630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost: False\n",
      "CatBoost: True\n",
      "\n",
      "1. Processing: 18 body parts\n",
      "  Single: (544859, 117)\n",
      "n_videos: 1, n_models: 4\n",
      "video with missing values 438887472 test 529471 frames\n",
      "- test single 438887472 1\n",
      "  actions found: 8\n",
      "- test single 438887472 2\n",
      "  actions found: 73\n",
      "- test single 438887472 3\n",
      "  actions found: 50\n",
      "- test single 438887472 4\n",
      "  actions found: 123\n",
      "  Pair: (1744248, 140)\n",
      "n_videos: 1, n_models: 4\n",
      "video with missing values 438887472 test 529471 frames\n",
      "- test pair 438887472 1 2\n",
      "  actions found: 0\n",
      "- test pair 438887472 1 3\n",
      "  actions found: 0\n",
      "- test pair 438887472 1 4\n",
      "  actions found: 10\n",
      "- test pair 438887472 2 1\n",
      "  actions found: 9\n",
      "- test pair 438887472 2 3\n",
      "  actions found: 21\n",
      "- test pair 438887472 2 4\n",
      "  actions found: 25\n",
      "- test pair 438887472 3 1\n",
      "  actions found: 13\n",
      "- test pair 438887472 3 2\n",
      "  actions found: 18\n",
      "- test pair 438887472 3 4\n",
      "  actions found: 21\n",
      "- test pair 438887472 4 1\n",
      "  actions found: 50\n",
      "- test pair 438887472 4 2\n",
      "  actions found: 41\n",
      "- test pair 438887472 4 3\n",
      "  actions found: 39\n",
      "\n",
      "2. Processing: 14 body parts\n",
      "  Single: (478728, 126)\n",
      "n_videos: 0, n_models: 4\n",
      "  Pair: (628714, 159)\n",
      "n_videos: 0, n_models: 4\n",
      "\n",
      "3. Processing: 10 body parts\n",
      "  Single: (1941885, 117)\n",
      "n_videos: 0, n_models: 4\n",
      "  Pair: (5880720, 140)\n",
      "n_videos: 0, n_models: 4\n",
      "\n",
      "4. Processing: 8 body parts\n",
      "  Pair: (2534176, 123)\n",
      "n_videos: 0, n_models: 4\n",
      "\n",
      "5. Processing: 7 body parts\n",
      "No labeled behaviors: SparklingTapir 139713291 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 167444193 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 329031399 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 361341393 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 484405601 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 610412175 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 687999061 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 801328824 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 834408298 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 1085312517 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 1366115611 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 1430299100 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 1543851393 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 1588709555 <class 'float'>\n",
      "No labeled behaviors: SparklingTapir 1772737271 <class 'float'>\n",
      "  Pair: (1849144, 108)\n",
      "n_videos: 0, n_models: 4\n",
      "\n",
      "6. Processing: 5 body parts\n",
      "  Single: (708496, 91)\n",
      "n_videos: 0, n_models: 4\n",
      "  Pair: (10212910, 84)\n",
      "n_videos: 0, n_models: 4\n",
      "\n",
      "7. Processing: 4 body parts\n",
      "  Single: (899134, 17)\n",
      "n_videos: 0, n_models: 4\n",
      "  Pair: (899134, 19)\n",
      "n_videos: 0, n_models: 4\n",
      "\n",
      "8. Processing: 7 body parts\n",
      "  Single: (3020371, 39)\n",
      "n_videos: 0, n_models: 4\n",
      "  Pair: (23086736, 63)\n",
      "n_videos: 0, n_models: 4\n",
      "\n",
      "9. Processing: 5 body parts\n",
      "  Single: (329777, 28)\n",
      "n_videos: 0, n_models: 4\n",
      "  Pair: (1774618, 39)\n",
      "n_videos: 0, n_models: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL: MAIN TRAINING LOOP (FPS-Aware Version from v4)\n",
    "# =============================================================================\n",
    "# %%time\n",
    "f1_list = []\n",
    "submission_list = []\n",
    "\n",
    "print(f\"XGBoost: {'XGBOOST_AVAILABLE' in globals() and XGBOOST_AVAILABLE}\")\n",
    "print(f\"CatBoost: {'CATBOOST_AVAILABLE' in globals() and CATBOOST_AVAILABLE}\\n\")\n",
    "\n",
    "for section in range(1, len(body_parts_tracked_list)):\n",
    "    body_parts_tracked_str = body_parts_tracked_list[section]\n",
    "    try:\n",
    "        body_parts_tracked = json.loads(body_parts_tracked_str)\n",
    "        print(f\"{section}. Processing: {len(body_parts_tracked)} body parts\")\n",
    "        if len(body_parts_tracked) > 5:\n",
    "            body_parts_tracked = [b for b in body_parts_tracked if b not in drop_body_parts]\n",
    "\n",
    "        train_subset = train[train.body_parts_tracked == body_parts_tracked_str]\n",
    "\n",
    "        _fps_lookup = (\n",
    "            train_subset[['video_id', 'frames_per_second']]\n",
    "            .drop_duplicates('video_id')\n",
    "            .set_index('video_id')['frames_per_second']\n",
    "            .to_dict()\n",
    "        )\n",
    "\n",
    "        single_list, single_label_list, single_meta_list = [], [], []\n",
    "        pair_list, pair_label_list, pair_meta_list = [], [], []\n",
    "\n",
    "        for switch, data, meta, label in generate_mouse_data(train_subset, 'train'):\n",
    "            if switch == 'single':\n",
    "                single_list.append(data)\n",
    "                single_meta_list.append(meta)\n",
    "                single_label_list.append(label)\n",
    "            else:\n",
    "                pair_list.append(data)\n",
    "                pair_meta_list.append(meta)\n",
    "                pair_label_list.append(label)\n",
    "\n",
    "        if len(single_list) > 0:\n",
    "            single_feats_parts = []\n",
    "            for data_i, meta_i in zip(single_list, single_meta_list):\n",
    "                fps_i = _fps_from_meta(meta_i, _fps_lookup, default_fps=30.0)\n",
    "                Xi = transform_single(data_i, body_parts_tracked, fps_i).astype(np.float32)\n",
    "                single_feats_parts.append(Xi)\n",
    "\n",
    "            X_tr = pd.concat(single_feats_parts, axis=0, ignore_index=True)\n",
    " \n",
    "            single_label = pd.concat(single_label_list, axis=0, ignore_index=True)\n",
    "            single_meta  = pd.concat(single_meta_list,  axis=0, ignore_index=True)\n",
    "\n",
    "            del single_list, single_label_list, single_meta_list, single_feats_parts\n",
    "            gc.collect()\n",
    "\n",
    "            print(f\"  Single: {X_tr.shape}\")\n",
    "            submit_ensemble(body_parts_tracked_str, 'single', X_tr, single_label, 2_000_000)\n",
    "\n",
    "            del X_tr, single_label, single_meta\n",
    "            gc.collect()\n",
    "\n",
    "        if len(pair_list) > 0:\n",
    "            pair_feats_parts = []\n",
    "            for data_i, meta_i in zip(pair_list, pair_meta_list):\n",
    "                fps_i = _fps_from_meta(meta_i, _fps_lookup, default_fps=30.0)\n",
    "                Xi = transform_pair(data_i, body_parts_tracked, fps_i).astype(np.float32)\n",
    "                pair_feats_parts.append(Xi)\n",
    "\n",
    "            X_tr = pd.concat(pair_feats_parts, axis=0, ignore_index=True)\n",
    "\n",
    "            \n",
    "            pair_label = pd.concat(pair_label_list, axis=0, ignore_index=True)\n",
    "            pair_meta  = pd.concat(pair_meta_list,  axis=0, ignore_index=True)\n",
    "\n",
    "            del pair_list, pair_label_list, pair_meta_list, pair_feats_parts\n",
    "            gc.collect()\n",
    "\n",
    "            print(f\"  Pair: {X_tr.shape}\")\n",
    "            submit_ensemble(body_parts_tracked_str, 'pair', X_tr, pair_label, 900_000)\n",
    "\n",
    "            del X_tr, pair_label, pair_meta\n",
    "            gc.collect()\n",
    "\n",
    "    except Exception as e:\n",
    "        error_msg = str(e)\n",
    "        if len(error_msg) > 200:\n",
    "            error_msg = error_msg[:200] + \"...\"\n",
    "        print(f'***Exception*** {error_msg}')\n",
    "        if verbose:\n",
    "            print(f'Traceback: {traceback.format_exc()[:500]}')\n",
    "\n",
    "    gc.collect()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "065691ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T19:28:12.995389Z",
     "iopub.status.busy": "2025-12-13T19:28:12.995148Z",
     "iopub.status.idle": "2025-12-13T19:28:13.004455Z",
     "shell.execute_reply": "2025-12-13T19:28:13.003709Z"
    },
    "papermill": {
     "duration": 0.018911,
     "end_time": "2025-12-13T19:28:13.005541",
     "exception": false,
     "start_time": "2025-12-13T19:28:12.986630",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def robustify(submission, dataset, traintest, traintest_directory=None):\n",
    "    \"\"\"Ensure that the submission conforms to the three rules (with security fix from v4)\"\"\"\n",
    "    if traintest_directory is None:\n",
    "        traintest_directory = f\"/kaggle/input/MABe-mouse-behavior-detection/{traintest}_tracking\"\n",
    "\n",
    "    # Rule 1: Ensure that start_frame < stop_frame\n",
    "    submission = submission[submission.start_frame < submission.stop_frame]\n",
    "    \n",
    "    # Rule 2: Avoid multiple predictions for the same frame from one agent/target pair\n",
    "    group_list = []\n",
    "    for _, group in submission.groupby(['video_id', 'agent_id', 'target_id']):\n",
    "        group = group.sort_values('start_frame')\n",
    "        mask = np.ones(len(group), dtype=bool)\n",
    "        last_stop = 0\n",
    "        for i, (_, row) in enumerate(group.iterrows()):\n",
    "            if row['start_frame'] < last_stop:\n",
    "                mask[i] = False\n",
    "            else:\n",
    "                last_stop = row['stop_frame']\n",
    "        group_list.append(group[mask])\n",
    "    submission = pd.concat(group_list) if group_list else submission\n",
    "\n",
    "    # Rule 3: Submit something for every video\n",
    "    s_list = []\n",
    "    for _, row in dataset.iterrows():\n",
    "        lab_id = row['lab_id']\n",
    "        video_id = row['video_id']\n",
    "        if (submission.video_id == video_id).any():\n",
    "            continue\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Video {video_id} has no predictions\")\n",
    "\n",
    "        path = f\"{traintest_directory}/{lab_id}/{video_id}.parquet\"\n",
    "        vid = pd.read_parquet(path)\n",
    "\n",
    "        # SECURITY FIX: Use json.loads instead of eval or ast.literal_eval\n",
    "        vid_behaviors = json.loads(row['behaviors_labeled'])\n",
    "        vid_behaviors = sorted(list({b.replace(\"'\", \"\") for b in vid_behaviors}))\n",
    "        vid_behaviors = [b.split(',') for b in vid_behaviors]\n",
    "        vid_behaviors = pd.DataFrame(vid_behaviors, columns=['agent', 'target', 'action'])\n",
    "\n",
    "        start_frame = vid.video_frame.min()\n",
    "        stop_frame = vid.video_frame.max() + 1\n",
    "\n",
    "        for (agent, target), actions in vid_behaviors.groupby(['agent', 'target']):\n",
    "            batch_len = int(np.ceil((stop_frame - start_frame) / len(actions)))\n",
    "            for i, (_, action_row) in enumerate(actions.iterrows()):\n",
    "                batch_start = start_frame + i * batch_len\n",
    "                batch_stop = min(batch_start + batch_len, stop_frame)\n",
    "                s_list.append((video_id, agent, target, action_row['action'], batch_start, batch_stop))\n",
    "\n",
    "    if len(s_list) > 0:\n",
    "        submission = pd.concat([\n",
    "            submission,\n",
    "            pd.DataFrame(s_list, columns=['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame'])\n",
    "        ])\n",
    "\n",
    "    submission = submission.reset_index(drop=True)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9da6d087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T19:28:13.021481Z",
     "iopub.status.busy": "2025-12-13T19:28:13.021269Z",
     "iopub.status.idle": "2025-12-13T19:28:13.024980Z",
     "shell.execute_reply": "2025-12-13T19:28:13.024478Z"
    },
    "papermill": {
     "duration": 0.012856,
     "end_time": "2025-12-13T19:28:13.025949",
     "exception": false,
     "start_time": "2025-12-13T19:28:13.013093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if validate_or_submit == 'validate':\n",
    "    # Score the oof predictions with the competition scoring function\n",
    "    submission = pd.concat(submission_list)\n",
    "    submission_robust = robustify(submission, train, 'train')\n",
    "    print(f\"# OOF score with competition metric: {score(solution, submission_robust, ''):.4f}\")\n",
    "\n",
    "    f1_df = pd.DataFrame(f1_list, columns=['body_parts_tracked_str', 'action', 'binary F1 score'])\n",
    "    print(f\"# Average of {len(f1_df)} binary F1 scores {f1_df['binary F1 score'].mean():.4f}\")\n",
    "    # with pd.option_context('display.max_rows', 500):\n",
    "    #     display(f1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2200c26d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T19:28:13.041854Z",
     "iopub.status.busy": "2025-12-13T19:28:13.041679Z",
     "iopub.status.idle": "2025-12-13T19:28:13.375754Z",
     "shell.execute_reply": "2025-12-13T19:28:13.374809Z"
    },
    "papermill": {
     "duration": 0.343858,
     "end_time": "2025-12-13T19:28:13.377206",
     "exception": false,
     "start_time": "2025-12-13T19:28:13.033348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_id,video_id,agent_id,target_id,action,start_frame,stop_frame\r\n",
      "0,438887472,mouse1,mouse4,submit,1427,1430\r\n",
      "1,438887472,mouse1,mouse4,submit,1431,1434\r\n",
      "2,438887472,mouse1,mouse4,attack,1436,1444\r\n",
      "3,438887472,mouse1,mouse4,attack,1449,1488\r\n",
      "4,438887472,mouse1,mouse4,submit,1491,1496\r\n",
      "5,438887472,mouse1,mouse4,attack,1508,1514\r\n",
      "6,438887472,mouse1,mouse4,attack,1515,1536\r\n",
      "7,438887472,mouse1,mouse4,attack,2415,2421\r\n",
      "8,438887472,mouse1,mouse4,avoid,2564,2591\r\n"
     ]
    }
   ],
   "source": [
    "if validate_or_submit != 'validate':\n",
    "    if len(submission_list) > 0:\n",
    "        submission = pd.concat(submission_list)\n",
    "    else:\n",
    "        submission = pd.DataFrame(\n",
    "            dict(\n",
    "                video_id=438887472,\n",
    "                agent_id='mouse1',\n",
    "                target_id='self',\n",
    "                action='rear',\n",
    "                start_frame=278,\n",
    "                stop_frame=500\n",
    "            ), index=[44])\n",
    "    if validate_or_submit == 'submit':\n",
    "        submission_robust = robustify(submission, test, 'test')\n",
    "    else:\n",
    "        submission_robust = robustify(submission, stresstest, 'stresstest', 'stresstest_tracking')\n",
    "    submission_robust.index.name = 'row_id'\n",
    "    submission_robust.to_csv('submission.csv')\n",
    "    !head submission.csv"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13874099,
     "sourceId": 59156,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6443.941511,
   "end_time": "2025-12-13T19:28:16.558812",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-13T17:40:52.617301",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
